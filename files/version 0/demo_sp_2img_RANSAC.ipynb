{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import glob\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import FundamentalMatrixTransform, AffineTransform\n",
    "\n",
    "# Stub to warn about opencv version.\n",
    "if int(cv2.__version__[0]) < 3: # pragma: no cover\n",
    "  print('Warning: OpenCV 3 is not installed')\n",
    "\n",
    "# Jet colormap for visualization.\n",
    "myjet = np.array([[0.        , 0.        , 0.5       ],\n",
    "                  [0.        , 0.        , 0.99910873],\n",
    "                  [0.        , 0.37843137, 1.        ],\n",
    "                  [0.        , 0.83333333, 1.        ],\n",
    "                  [0.30044276, 1.        , 0.66729918],\n",
    "                  [0.66729918, 1.        , 0.30044276],\n",
    "                  [1.        , 0.90123457, 0.        ],\n",
    "                  [1.        , 0.48002905, 0.        ],\n",
    "                  [0.99910873, 0.07334786, 0.        ],\n",
    "                  [0.5       , 0.        , 0.        ]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperPointNet(torch.nn.Module):\n",
    "  \"\"\" Pytorch definition of SuperPoint Network. \"\"\"\n",
    "  def __init__(self):\n",
    "    super(SuperPointNet, self).__init__()\n",
    "    self.relu = torch.nn.ReLU(inplace=True)\n",
    "    self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    c1, c2, c3, c4, c5, d1 = 64, 64, 128, 128, 256, 256\n",
    "    # Shared Encoder.\n",
    "    self.conv1a = torch.nn.Conv2d(1, c1, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv1b = torch.nn.Conv2d(c1, c1, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv2a = torch.nn.Conv2d(c1, c2, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv2b = torch.nn.Conv2d(c2, c2, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv3a = torch.nn.Conv2d(c2, c3, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv3b = torch.nn.Conv2d(c3, c3, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv4a = torch.nn.Conv2d(c3, c4, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv4b = torch.nn.Conv2d(c4, c4, kernel_size=3, stride=1, padding=1)\n",
    "    # Detector Head.\n",
    "    self.convPa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
    "    self.convPb = torch.nn.Conv2d(c5, 65, kernel_size=1, stride=1, padding=0)\n",
    "    # Descriptor Head.\n",
    "    self.convDa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
    "    self.convDb = torch.nn.Conv2d(c5, d1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\" Forward pass that jointly computes unprocessed point and descriptor\n",
    "    tensors.\n",
    "    Input\n",
    "      x: Image pytorch tensor shaped N x 1 x H x W.\n",
    "    Output\n",
    "      semi: Output point pytorch tensor shaped N x 65 x H/8 x W/8.\n",
    "      desc: Output descriptor pytorch tensor shaped N x 256 x H/8 x W/8.\n",
    "    \"\"\"\n",
    "    # Shared Encoder.\n",
    "    x = self.relu(self.conv1a(x))\n",
    "    x = self.relu(self.conv1b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv2a(x))\n",
    "    x = self.relu(self.conv2b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv3a(x))\n",
    "    x = self.relu(self.conv3b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv4a(x))\n",
    "    x = self.relu(self.conv4b(x))\n",
    "    # Detector Head.\n",
    "    cPa = self.relu(self.convPa(x))\n",
    "    semi = self.convPb(cPa)\n",
    "    # Descriptor Head.\n",
    "    cDa = self.relu(self.convDa(x))\n",
    "    desc = self.convDb(cDa)\n",
    "    dn = torch.norm(desc, p=2, dim=1) # Compute the norm.\n",
    "    desc = desc.div(torch.unsqueeze(dn, 1)) # Divide by norm to normalize.\n",
    "    return semi, desc\n",
    "\n",
    "\n",
    "class SuperPointFrontend(object):\n",
    "  \"\"\" Wrapper around pytorch net to help with pre and post image processing. \"\"\"\n",
    "  def __init__(self, weights_path, nms_dist, conf_thresh, nn_thresh,\n",
    "               cuda=False):\n",
    "    self.name = 'SuperPoint'\n",
    "    self.cuda = cuda\n",
    "    self.nms_dist = nms_dist\n",
    "    self.conf_thresh = conf_thresh\n",
    "    self.nn_thresh = nn_thresh # L2 descriptor distance for good match.\n",
    "    self.cell = 8 # Size of each output cell. Keep this fixed.\n",
    "    self.border_remove = 4 # Remove points this close to the border.\n",
    "\n",
    "    # Load the network in inference mode.\n",
    "    self.net = SuperPointNet()\n",
    "    if cuda:\n",
    "      # Train on GPU, deploy on GPU.\n",
    "      self.net.load_state_dict(torch.load(weights_path))\n",
    "      self.net = self.net.cuda()\n",
    "    else:\n",
    "      # Train on GPU, deploy on CPU.\n",
    "      self.net.load_state_dict(torch.load(weights_path,\n",
    "                               map_location=lambda storage, loc: storage))\n",
    "    self.net.eval()\n",
    "\n",
    "  def nms_fast(self, in_corners, H, W, dist_thresh):\n",
    "    \"\"\"\n",
    "    Run a faster approximate Non-Max-Suppression on numpy corners shaped:\n",
    "      3xN [x_i,y_i,conf_i]^T\n",
    "  \n",
    "    Algo summary: Create a grid sized HxW. Assign each corner location a 1, rest\n",
    "    are zeros. Iterate through all the 1's and convert them either to -1 or 0.\n",
    "    Suppress points by setting nearby values to 0.\n",
    "  \n",
    "    Grid Value Legend:\n",
    "    -1 : Kept.\n",
    "     0 : Empty or suppressed.\n",
    "     1 : To be processed (converted to either kept or supressed).\n",
    "  \n",
    "    NOTE: The NMS first rounds points to integers, so NMS distance might not\n",
    "    be exactly dist_thresh. It also assumes points are within image boundaries.\n",
    "  \n",
    "    Inputs\n",
    "      in_corners - 3xN numpy array with corners [x_i, y_i, confidence_i]^T.\n",
    "      H - Image height.\n",
    "      W - Image width.\n",
    "      dist_thresh - Distance to suppress, measured as an infinty norm distance.\n",
    "    Returns\n",
    "      nmsed_corners - 3xN numpy matrix with surviving corners.\n",
    "      nmsed_inds - N length numpy vector with surviving corner indices.\n",
    "    \"\"\"\n",
    "    grid = np.zeros((H, W)).astype(int) # Track NMS data.\n",
    "    inds = np.zeros((H, W)).astype(int) # Store indices of points.\n",
    "    # Sort by confidence and round to nearest int.\n",
    "    inds1 = np.argsort(-in_corners[2,:])\n",
    "    corners = in_corners[:,inds1]\n",
    "    rcorners = corners[:2,:].round().astype(int) # Rounded corners.\n",
    "    # Check for edge case of 0 or 1 corners.\n",
    "    if rcorners.shape[1] == 0:\n",
    "      return np.zeros((3,0)).astype(int), np.zeros(0).astype(int)\n",
    "    if rcorners.shape[1] == 1:\n",
    "      out = np.vstack((rcorners, in_corners[2])).reshape(3,1)\n",
    "      return out, np.zeros((1)).astype(int)\n",
    "    # Initialize the grid.\n",
    "    for i, rc in enumerate(rcorners.T):\n",
    "      grid[rcorners[1,i], rcorners[0,i]] = 1\n",
    "      inds[rcorners[1,i], rcorners[0,i]] = i\n",
    "    # Pad the border of the grid, so that we can NMS points near the border.\n",
    "    pad = dist_thresh\n",
    "    grid = np.pad(grid, ((pad,pad), (pad,pad)), mode='constant')\n",
    "    # Iterate through points, highest to lowest conf, suppress neighborhood.\n",
    "    count = 0\n",
    "    for i, rc in enumerate(rcorners.T):\n",
    "      # Account for top and left padding.\n",
    "      pt = (rc[0]+pad, rc[1]+pad)\n",
    "      if grid[pt[1], pt[0]] == 1: # If not yet suppressed.\n",
    "        grid[pt[1]-pad:pt[1]+pad+1, pt[0]-pad:pt[0]+pad+1] = 0\n",
    "        grid[pt[1], pt[0]] = -1\n",
    "        count += 1\n",
    "    # Get all surviving -1's and return sorted array of remaining corners.\n",
    "    keepy, keepx = np.where(grid==-1)\n",
    "    keepy, keepx = keepy - pad, keepx - pad\n",
    "    inds_keep = inds[keepy, keepx]\n",
    "    out = corners[:, inds_keep]\n",
    "    values = out[-1, :]\n",
    "    inds2 = np.argsort(-values)\n",
    "    out = out[:, inds2]\n",
    "    out_inds = inds1[inds_keep[inds2]]\n",
    "    return out, out_inds\n",
    "\n",
    "  def run(self, img):\n",
    "    \"\"\" Process a numpy image to extract points and descriptors.\n",
    "    Input\n",
    "      img - HxW numpy float32 input image in range [0,1].\n",
    "    Output\n",
    "      corners - 3xN numpy array with corners [x_i, y_i, confidence_i]^T.\n",
    "      desc - 256xN numpy array of corresponding unit normalized descriptors.\n",
    "      heatmap - HxW numpy heatmap in range [0,1] of point confidences.\n",
    "      \"\"\"\n",
    "    assert img.ndim == 2, 'Image must be grayscale.'\n",
    "    assert img.dtype == np.float32, 'Image must be float32.'\n",
    "    H, W = img.shape[0], img.shape[1]\n",
    "    inp = img.copy()\n",
    "    inp = (inp.reshape(1, H, W))\n",
    "    inp = torch.from_numpy(inp)\n",
    "    inp = torch.autograd.Variable(inp).view(1, 1, H, W)\n",
    "    if self.cuda:\n",
    "      inp = inp.cuda()\n",
    "    # Forward pass of network.\n",
    "    outs = self.net.forward(inp)\n",
    "    semi, coarse_desc = outs[0], outs[1]\n",
    "    # Convert pytorch -> numpy.\n",
    "    semi = semi.data.cpu().numpy().squeeze()\n",
    "    # --- Process points.\n",
    "    dense = np.exp(semi) # Softmax.\n",
    "    dense = dense / (np.sum(dense, axis=0)+.00001) # Should sum to 1.\n",
    "    # Remove dustbin.\n",
    "    nodust = dense[:-1, :, :]\n",
    "    # Reshape to get full resolution heatmap.\n",
    "    Hc = int(H / self.cell)\n",
    "    Wc = int(W / self.cell)\n",
    "    nodust = nodust.transpose(1, 2, 0)\n",
    "    heatmap = np.reshape(nodust, [Hc, Wc, self.cell, self.cell])\n",
    "    heatmap = np.transpose(heatmap, [0, 2, 1, 3])\n",
    "    heatmap = np.reshape(heatmap, [Hc*self.cell, Wc*self.cell])\n",
    "    xs, ys = np.where(heatmap >= self.conf_thresh) # Confidence threshold.\n",
    "    if len(xs) == 0:\n",
    "      return np.zeros((3, 0)), None, None\n",
    "    pts = np.zeros((3, len(xs))) # Populate point data sized 3xN.\n",
    "    pts[0, :] = ys\n",
    "    pts[1, :] = xs\n",
    "    pts[2, :] = heatmap[xs, ys]\n",
    "    pts, _ = self.nms_fast(pts, H, W, dist_thresh=self.nms_dist) # Apply NMS.\n",
    "    inds = np.argsort(pts[2,:])\n",
    "    pts = pts[:,inds[::-1]] # Sort by confidence.\n",
    "    # Remove points along border.\n",
    "    bord = self.border_remove\n",
    "    toremoveW = np.logical_or(pts[0, :] < bord, pts[0, :] >= (W-bord))\n",
    "    toremoveH = np.logical_or(pts[1, :] < bord, pts[1, :] >= (H-bord))\n",
    "    toremove = np.logical_or(toremoveW, toremoveH)\n",
    "    pts = pts[:, ~toremove]\n",
    "    # --- Process descriptor.\n",
    "    D = coarse_desc.shape[1]\n",
    "    if pts.shape[1] == 0:\n",
    "      desc = np.zeros((D, 0))\n",
    "    else:\n",
    "      # Interpolate into descriptor map using 2D point locations.\n",
    "      samp_pts = torch.from_numpy(pts[:2, :].copy())\n",
    "      samp_pts[0, :] = (samp_pts[0, :] / (float(W)/2.)) - 1.\n",
    "      samp_pts[1, :] = (samp_pts[1, :] / (float(H)/2.)) - 1.\n",
    "      samp_pts = samp_pts.transpose(0, 1).contiguous()\n",
    "      samp_pts = samp_pts.view(1, 1, -1, 2)\n",
    "      samp_pts = samp_pts.float()\n",
    "      if self.cuda:\n",
    "        samp_pts = samp_pts.cuda()\n",
    "      desc = torch.nn.functional.grid_sample(coarse_desc, samp_pts)\n",
    "      desc = desc.data.cpu().numpy().reshape(D, -1)\n",
    "      desc /= np.linalg.norm(desc, axis=0)[np.newaxis, :]\n",
    "    return pts, desc, heatmap\n",
    "\n",
    "\n",
    "class PointTracker(object):\n",
    "  \"\"\" Class to manage a fixed memory of points and descriptors that enables\n",
    "  sparse optical flow point tracking.\n",
    "\n",
    "  Internally, the tracker stores a 'tracks' matrix sized M x (2+L), of M\n",
    "  tracks with maximum length L, where each row corresponds to:\n",
    "  row_m = [track_id_m, avg_desc_score_m, point_id_0_m, ..., point_id_L-1_m].\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, max_length, nn_thresh):\n",
    "    if max_length < 2:\n",
    "      raise ValueError('max_length must be greater than or equal to 2.')\n",
    "    self.maxl = max_length\n",
    "    self.nn_thresh = nn_thresh\n",
    "    self.all_pts = []\n",
    "    for n in range(self.maxl):\n",
    "      self.all_pts.append(np.zeros((2, 0)))\n",
    "    self.last_desc = None\n",
    "    self.tracks = np.zeros((0, self.maxl+2))\n",
    "    self.track_count = 0\n",
    "    self.max_score = 9999\n",
    "\n",
    "  def nn_match_two_way(self, desc1, desc2, nn_thresh):\n",
    "    \"\"\"\n",
    "    Performs two-way nearest neighbor matching of two sets of descriptors, such\n",
    "    that the NN match from descriptor A->B must equal the NN match from B->A.\n",
    "\n",
    "    Inputs:\n",
    "      desc1 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      desc2 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      nn_thresh - Optional descriptor distance below which is a good match.\n",
    "\n",
    "    Returns:\n",
    "      matches - 3xL numpy array, of L matches, where L <= N and each column i is\n",
    "                a match of two descriptors, d_i in image 1 and d_j' in image 2:\n",
    "                [d_i index, d_j' index, match_score]^T\n",
    "    \"\"\"\n",
    "    assert desc1.shape[0] == desc2.shape[0]\n",
    "    if desc1.shape[1] == 0 or desc2.shape[1] == 0:\n",
    "      return np.zeros((3, 0))\n",
    "    if nn_thresh < 0.0:\n",
    "      raise ValueError('\\'nn_thresh\\' should be non-negative')\n",
    "    # Compute L2 distance. Easy since vectors are unit normalized.\n",
    "    dmat = np.dot(desc1.T, desc2)\n",
    "    dmat = np.sqrt(2-2*np.clip(dmat, -1, 1))\n",
    "    # Get NN indices and scores.\n",
    "    idx = np.argmin(dmat, axis=1)\n",
    "    scores = dmat[np.arange(dmat.shape[0]), idx]\n",
    "    # Threshold the NN matches.  <<< ======================= this threshold is not good\n",
    "    keep = scores < nn_thresh\n",
    "    # Check if nearest neighbor goes both directions and keep those.\n",
    "    idx2 = np.argmin(dmat, axis=0)\n",
    "    keep_bi = np.arange(len(idx)) == idx2[idx]\n",
    "    keep = np.logical_and(keep, keep_bi)\n",
    "    idx = idx[keep]\n",
    "    scores = scores[keep]\n",
    "    # Get the surviving point indices.\n",
    "    m_idx1 = np.arange(desc1.shape[1])[keep]\n",
    "    m_idx2 = idx\n",
    "    # Populate the final 3xN match data structure.\n",
    "    matches = np.zeros((3, int(keep.sum())))\n",
    "    matches[0, :] = m_idx1\n",
    "    matches[1, :] = m_idx2\n",
    "    matches[2, :] = scores\n",
    "    return matches\n",
    "  \n",
    "  def nn_match_two_way_with_ransac(self, points1, points2, matches, max_reproj_error=5.0):  # <<=========================================== TODO Here is the RANSAC\n",
    "    '''find matching points between two images using RANSAC'''\n",
    "    \n",
    "    # estimate affine transform model using all coordinates\n",
    "    model = AffineTransform()\n",
    "    model.estimate(points1, points2)\n",
    "\n",
    "    # try min_samples = 3, if fail, try min_samples = 2\n",
    "    try:\n",
    "      # Find the best fundamental matrix using RANSAC\n",
    "      best_model, best_inliers = ransac((points1, points2),\n",
    "                                        AffineTransform, min_samples=3,\n",
    "                                        residual_threshold=max_reproj_error, max_trials=100)\n",
    "    except:\n",
    "      try:\n",
    "        best_model, best_inliers = ransac((points1, points2),\n",
    "                                          AffineTransform, min_samples=2,\n",
    "                                          residual_threshold=max_reproj_error, max_trials=100)\n",
    "        \n",
    "      except:\n",
    "        # if ransac failed, return an array of TRUE with the original matches shape\n",
    "        print('ransac failed')\n",
    "        print('matches shape: ', matches.shape)\n",
    "        return np.ones((matches.shape[1])).astype(bool)\n",
    "    \n",
    "    # the inliners are the matching points\n",
    "    matches = np.array(best_inliers).T\n",
    "\n",
    "    print(f'matches: {matches.shape}')\n",
    "    return matches\n",
    "\n",
    "  def get_offsets(self):\n",
    "    \"\"\" Iterate through list of points and accumulate an offset value. Used to\n",
    "    index the global point IDs into the list of points.\n",
    "\n",
    "    Returns\n",
    "      offsets - N length array with integer offset locations.\n",
    "    \"\"\"\n",
    "    # Compute id offsets.\n",
    "    offsets = []\n",
    "    offsets.append(0)\n",
    "    for i in range(len(self.all_pts)-1): # Skip last camera size, not needed.\n",
    "      offsets.append(self.all_pts[i].shape[1])\n",
    "    offsets = np.array(offsets)\n",
    "    offsets = np.cumsum(offsets)\n",
    "    return offsets\n",
    "\n",
    "  def update(self, pts, desc):\n",
    "    \"\"\" Add a new set of point and descriptor observations to the tracker.\n",
    "\n",
    "    Inputs\n",
    "      pts - 3xN numpy array of 2D point observations.\n",
    "      desc - DxN numpy array of corresponding D dimensional descriptors.\n",
    "    \"\"\"\n",
    "    if pts is None or desc is None:\n",
    "      print('PointTracker: Warning, no points were added to tracker.')\n",
    "      return\n",
    "    assert pts.shape[1] == desc.shape[1]\n",
    "    # Initialize last_desc.\n",
    "    if self.last_desc is None:\n",
    "      self.last_desc = np.zeros((desc.shape[0], 0))\n",
    "    # Remove oldest points, store its size to update ids later.\n",
    "    remove_size = self.all_pts[0].shape[1]\n",
    "    self.all_pts.pop(0)\n",
    "    self.all_pts.append(pts)\n",
    "    # Remove oldest point in track.\n",
    "    self.tracks = np.delete(self.tracks, 2, axis=1)\n",
    "    # Update track offsets.\n",
    "    for i in range(2, self.tracks.shape[1]):\n",
    "      self.tracks[:, i] -= remove_size\n",
    "    self.tracks[:, 2:][self.tracks[:, 2:] < -1] = -1\n",
    "    offsets = self.get_offsets()\n",
    "    # Add a new -1 column.\n",
    "    self.tracks = np.hstack((self.tracks, -1*np.ones((self.tracks.shape[0], 1))))\n",
    "    # Try to append to existing tracks.\n",
    "    matched = np.zeros((pts.shape[1])).astype(bool)\n",
    "    matches = self.nn_match_two_way(self.last_desc, desc, self.nn_thresh)\n",
    "    for match in matches.T:\n",
    "      # Add a new point to it's matched track.\n",
    "      id1 = int(match[0]) + offsets[-2]\n",
    "      id2 = int(match[1]) + offsets[-1]\n",
    "      found = np.argwhere(self.tracks[:, -2] == id1)\n",
    "      if found.shape[0] > 0:\n",
    "        matched[int(match[1])] = True\n",
    "        row = int(found)\n",
    "        self.tracks[row, -1] = id2\n",
    "        if self.tracks[row, 1] == self.max_score:\n",
    "          # Initialize track score.\n",
    "          self.tracks[row, 1] = match[2]\n",
    "        else:\n",
    "          # Update track score with running average.\n",
    "          # NOTE(dd): this running average can contain scores from old matches\n",
    "          #           not contained in last max_length track points.\n",
    "          track_len = (self.tracks[row, 2:] != -1).sum() - 1.\n",
    "          frac = 1. / float(track_len)\n",
    "          self.tracks[row, 1] = (1.-frac)*self.tracks[row, 1] + frac*match[2]\n",
    "    # Add unmatched tracks.\n",
    "    new_ids = np.arange(pts.shape[1]) + offsets[-1]\n",
    "    new_ids = new_ids[~matched]\n",
    "    new_tracks = -1*np.ones((new_ids.shape[0], self.maxl + 2))\n",
    "    new_tracks[:, -1] = new_ids\n",
    "    new_num = new_ids.shape[0]\n",
    "    new_trackids = self.track_count + np.arange(new_num)\n",
    "    new_tracks[:, 0] = new_trackids\n",
    "    new_tracks[:, 1] = self.max_score*np.ones(new_ids.shape[0])\n",
    "    self.tracks = np.vstack((self.tracks, new_tracks))\n",
    "    self.track_count += new_num # Update the track count.\n",
    "    # Remove empty tracks.\n",
    "    keep_rows = np.any(self.tracks[:, 2:] >= 0, axis=1)\n",
    "    self.tracks = self.tracks[keep_rows, :]\n",
    "    # Store the last descriptors.\n",
    "    self.last_desc = desc.copy()\n",
    "    return\n",
    "\n",
    "  def get_tracks(self, min_length):\n",
    "    \"\"\" Retrieve point tracks of a given minimum length.\n",
    "    Input\n",
    "      min_length - integer >= 1 with minimum track length\n",
    "    Output\n",
    "      returned_tracks - M x (2+L) sized matrix storing track indices, where\n",
    "        M is the number of tracks and L is the maximum track length.\n",
    "    \"\"\"\n",
    "    if min_length < 1:\n",
    "      raise ValueError('\\'min_length\\' too small.')\n",
    "    valid = np.ones((self.tracks.shape[0])).astype(bool)\n",
    "    good_len = np.sum(self.tracks[:, 2:] != -1, axis=1) >= min_length\n",
    "    # Remove tracks which do not have an observation in most recent frame.\n",
    "    not_headless = (self.tracks[:, -1] != -1)\n",
    "    keepers = np.logical_and.reduce((valid, good_len, not_headless))\n",
    "    returned_tracks = self.tracks[keepers, :].copy()\n",
    "    return returned_tracks\n",
    "\n",
    "  def draw_tracks(self, out, tracks):\n",
    "    \"\"\" Visualize tracks all overlayed on a single image.\n",
    "    Inputs\n",
    "      out - numpy uint8 image sized HxWx3 upon which tracks are overlayed.\n",
    "      tracks - M x (2+L) sized matrix storing track info.\n",
    "    \"\"\"\n",
    "    # Store the number of points per camera.\n",
    "    pts_mem = self.all_pts\n",
    "    N = len(pts_mem) # Number of cameras/images.\n",
    "    # Get offset ids needed to reference into pts_mem.\n",
    "    offsets = self.get_offsets()\n",
    "    # Width of track and point circles to be drawn.\n",
    "    stroke = 1\n",
    "    # Iterate through each track and draw it.\n",
    "    for track in tracks:\n",
    "      clr = myjet[int(np.clip(np.floor(track[1]*10), 0, 9)), :]*255\n",
    "      for i in range(N-1):\n",
    "        if track[i+2] == -1 or track[i+3] == -1:\n",
    "          continue\n",
    "        offset1 = offsets[i]\n",
    "        offset2 = offsets[i+1]\n",
    "        idx1 = int(track[i+2]-offset1)\n",
    "        idx2 = int(track[i+3]-offset2)\n",
    "        pt1 = pts_mem[i][:2, idx1]\n",
    "        pt2 = pts_mem[i+1][:2, idx2]\n",
    "        p1 = (int(round(pt1[0])), int(round(pt1[1])))\n",
    "        p2 = (int(round(pt2[0])), int(round(pt2[1])))\n",
    "        cv2.line(out, p1, p2, clr, thickness=stroke, lineType=16)\n",
    "        # Draw end points of each track.\n",
    "        if i == N-2:\n",
    "          clr2 = (255, 0, 0)\n",
    "          cv2.circle(out, p2, stroke, clr2, -1, lineType=16)\n",
    "\n",
    "  def read_image(self, impath, img_size):\n",
    "    \"\"\" Read image as grayscale and resize to img_size.\n",
    "    Inputs\n",
    "      impath: Path to input image.\n",
    "      img_size: (W, H) tuple specifying resize size.\n",
    "    Returns\n",
    "      grayim: float32 numpy array sized H x W with values in range [0, 1].\n",
    "    \"\"\"\n",
    "    grayim = cv2.imread(impath, 0)\n",
    "    if grayim is None:\n",
    "      raise Exception('Error reading image %s' % impath)\n",
    "    # Image is resized via opencv.\n",
    "    interp = cv2.INTER_AREA\n",
    "    grayim = cv2.resize(grayim, (img_size[1], img_size[0]), interpolation=interp)\n",
    "    grayim = (grayim.astype('float32') / 255.)\n",
    "    return grayim\n",
    "\n",
    "  def next_frame(self):\n",
    "    \"\"\" Return the next frame, and increment internal counter.\n",
    "    Returns\n",
    "       image: Next H x W image.\n",
    "       status: True or False depending whether image was loaded.\n",
    "    \"\"\"\n",
    "    if self.i == self.maxlen:\n",
    "      return (None, False)\n",
    "    if self.camera:\n",
    "      ret, input_image = self.cap.read()\n",
    "      if ret is False:\n",
    "        print('VideoStreamer: Cannot get image from camera (maybe bad --camid?)')\n",
    "        return (None, False)\n",
    "      if self.video_file:\n",
    "        self.cap.set(cv2.CAP_PROP_POS_FRAMES, self.listing[self.i])\n",
    "      input_image = cv2.resize(input_image, (self.sizer[1], self.sizer[0]),\n",
    "                               interpolation=cv2.INTER_AREA)\n",
    "      input_image = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)\n",
    "      input_image = input_image.astype('float')/255.0\n",
    "    else:\n",
    "      image_file = self.listing[self.i]\n",
    "      input_image = self.read_image(image_file, self.sizer)\n",
    "    # Increment internal counter.\n",
    "    self.i = self.i + 1\n",
    "    input_image = input_image.astype('float32')\n",
    "    return (input_image, True)\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modified code to load and feed 2 images "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to overlay points on the image\n",
    "def overlay_points(image, points, color=(0, 255, 0), radius=5):\n",
    "    for point in points.T:\n",
    "        x, y = int(point[0]), int(point[1])\n",
    "        cv2.circle(image, (x, y), radius, color, -1)\n",
    "    return image\n",
    "\n",
    "# Predefined bright colors\n",
    "bright_colors = [\n",
    "    (255, 0, 0),    # Red\n",
    "    (0, 255, 0),    # Green\n",
    "    (0, 0, 255),    # Blue\n",
    "    (255, 255, 0),  # Yellow\n",
    "    (0, 255, 255),  # Cyan\n",
    "    (255, 0, 255),  # Magenta\n",
    "    (255, 128, 0),  # Orange\n",
    "    (0, 255, 128),  # Spring Green\n",
    "    (128, 0, 255),  # Purple\n",
    "    (255, 0, 128),  # Rose\n",
    "]\n",
    "\n",
    "# Function to draw lines connecting points from image 1 to image 2 with random bright colors\n",
    "def draw_lines(image1, image2, points1, points2, match, line_thickness=1, opacity=0.5):\n",
    "    # Convert grayscale images to 3-channel with repeated intensity value\n",
    "    if len(image1.shape) == 2:\n",
    "        image1 = cv2.cvtColor(image1, cv2.COLOR_GRAY2BGR)\n",
    "    if len(image2.shape) == 2:\n",
    "        image2 = cv2.cvtColor(image2, cv2.COLOR_GRAY2BGR)\n",
    "\n",
    "    combined_image = np.concatenate((image1, image2), axis=1)\n",
    "    for pt1, pt2, value in zip(points1.T, points2.T, match):\n",
    "        x1, y1 = int(pt1[0]), int(pt1[1])\n",
    "        x2, y2 = int(pt2[0] + image1.shape[1]), int(pt2[1])\n",
    "\n",
    "        # Randomly choose a color from the predefined bright colors\n",
    "        line_color = random.choice(bright_colors)\n",
    "\n",
    "        # Draw the line with the chosen color and specified thickness\n",
    "        cv2.line(combined_image, (x1, y1), (x2, y2), line_color, line_thickness)\n",
    "\n",
    "        # Add lines with the chosen color and opacity on top of the combined image\n",
    "        overlay = combined_image.copy()\n",
    "        cv2.line(overlay, (x1, y1), (x2, y2), line_color, line_thickness)\n",
    "        cv2.addWeighted(overlay, opacity, combined_image, 1 - opacity, 0, combined_image)\n",
    "\n",
    "        # Add value from 'match' array as text around the beginning of the line on the left image\n",
    "        value_text = f\"{value:.2f}\"\n",
    "        text_x = x1 - 50 if x1 > 50 else x1 + 10\n",
    "        text_y = y1 + 15\n",
    "        cv2.putText(combined_image, value_text, (text_x, text_y),\n",
    "                    cv2.FONT_HERSHEY_SIMPLEX, 0.5, line_color, 1)\n",
    "\n",
    "    return combined_image\n",
    "\n",
    "# Function to create a heatmap from keypoints\n",
    "def create_heatmap(image, keypoints, size=5, sigma=1):\n",
    "    heatmap = np.zeros_like(image)\n",
    "    for kp in keypoints.T:\n",
    "        x, y = int(kp[0]), int(kp[1])\n",
    "        heatmap[y - size:y + size + 1, x - size:x + size + 1] = 1\n",
    "    heatmap = cv2.GaussianBlur(heatmap, (0, 0), sigmaX=sigma, sigmaY=sigma)\n",
    "    return heatmap\n",
    "\n",
    "def create_subplot(name, image1_name, image2_name, image1, image2, points1, points2, \n",
    "                   heatmap1, heatmap2, match_score):\n",
    "    # Create a subplot with 2 rows and 2 columns\n",
    "    fig, axes = plt.subplot_mosaic(\"AAA;BCD\", figsize=(15, 10))\n",
    "\n",
    "    overlaid1 = overlay_points(image1.copy(), points1, radius=2)\n",
    "    overlaid2 = overlay_points(image2.copy(), points2, radius=2)\n",
    "\n",
    "    # offset the points in image 2 by the width of image 1\n",
    "    #points2[:, 0] += image1.shape[1]\n",
    "    \n",
    "    # Row 1: Two images side-by-side with overlaid points and lines\n",
    "    # show also MSE and SSIM between the two images\n",
    "    axes[\"A\"].imshow(draw_lines(overlaid1, overlaid2, points1, points2, match_score))\n",
    "    axes[\"A\"].set_title(f\"(RANSAC) Image {image1_name} & {image2_name} with Points. MSE (x100): {100*np.mean((image1 - image2)**2):.2f} SSIM: {ssim(image1, image2):.2f}\")\n",
    "    axes[\"A\"].axis('off')\n",
    "    \n",
    "    # Row 2: Heatmap for image 1 and image 2\n",
    "    axes[\"B\"].imshow(image1, cmap='gray')\n",
    "    axes[\"B\"].imshow(heatmap1, cmap='hot', alpha=0.8)\n",
    "    axes[\"B\"].set_title(\"Heatmap for Image 1\")\n",
    "    axes[\"B\"].axis('off')\n",
    "\n",
    "    axes[\"C\"].imshow(image2, cmap='gray')\n",
    "    axes[\"C\"].imshow(heatmap2, cmap='hot', alpha=0.8)\n",
    "    axes[\"C\"].set_title(\"Heatmap for Image 2\")\n",
    "    axes[\"C\"].axis('off')\n",
    "\n",
    "    # New subplot for histograms of 'match_score' array\n",
    "    axes[\"D\"].hist(match_score, bins=20, color='blue', alpha=0.7)\n",
    "    axes[\"D\"].set_title(f\"Match Score Histogram, {len(match_score)} matches\")\n",
    "    axes[\"D\"].set_xlabel(\"Value\")\n",
    "    axes[\"D\"].set_ylabel(\"Frequency\")\n",
    "    \n",
    "    plt.tight_layout()  # Adjust the layout to leave space for the histogram\n",
    "    os.makedirs('output_images', exist_ok=True)\n",
    "    plt.savefig(f\"output_images/{name}_{image1_name}_{image2_name}_RANSAC.png\")\n",
    "    plt.close()\n",
    "\n",
    "def check_location(points):\n",
    "    # check if the location of the points in array is within the image\n",
    "    # return the number of points that are outside the image\n",
    "    # points is a 2D array of shape (2, N)\n",
    "    # where N is the number of points\n",
    "    # the first row is the x coordinate\n",
    "    # the second row is the y coordinate\n",
    "    # the image size is 512 x 512\n",
    "    # the points are assumed to be in the range of 0 to 511\n",
    "    # return the number of points that are outside the image\n",
    "    number_outside = np.sum((points < 0) | (points > 511))\n",
    "    \n",
    "    # print if there are points outside the image\n",
    "    if number_outside > 0:\n",
    "        print(f'Number of points outside the image: {number_outside}')\n",
    "    # return number_outside\n",
    "\n",
    "def load_images_from_folder(folder, img_size=(512, 512)):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        img_path = os.path.join(folder, filename)\n",
    "        grayim = cv2.imread(img_path, 0)\n",
    "        interp = cv2.INTER_AREA\n",
    "        grayim = cv2.resize(grayim, (img_size[1], img_size[0]), interpolation=interp)\n",
    "        image = (grayim.astype('float32') / 255.)\n",
    "        if image is not None:\n",
    "            images.append(image)\n",
    "    return images\n",
    "\n",
    "def main(folder_path, name, weights_path='superpoint_v1.pth', cuda=True):\n",
    "    # Load all images from the folder\n",
    "    images = load_images_from_folder(folder_path)\n",
    "\n",
    "    if len(images) < 2:\n",
    "        print(\"At least 2 images are required in the folder.\")\n",
    "        return\n",
    "\n",
    "    # Initialize SuperPointFrontend\n",
    "    superpoint = SuperPointFrontend(weights_path, nms_dist=4,\n",
    "                          conf_thresh=0.015,\n",
    "                          nn_thresh=0.7, cuda=cuda)\n",
    "\n",
    "    # Process all pairs of images\n",
    "    for i in range(len(images)):\n",
    "        for j in range(i + 1, len(images)):\n",
    "            print(f'\\nImage {i} & {j}')\n",
    "            image1 = images[i]\n",
    "            image2 = images[j]\n",
    "\n",
    "            # Process the first image\n",
    "            points1, desc1, heatmap1 = superpoint.run(image1)\n",
    "\n",
    "            # Process the second image\n",
    "            points2, desc2, heatmap2 = superpoint.run(image2)\n",
    "\n",
    "            # check if the location of the points in array is within the image\n",
    "            check_location(points1)\n",
    "            check_location(points2)\n",
    "\n",
    "            # match the points between the two images\n",
    "            tracker = PointTracker(5, nn_thresh=0.7)\n",
    "            matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=0.7)\n",
    "\n",
    "            # take the elements from points1 and points2 using the matches as indices\n",
    "            matches1 = points1[:, matches[0, :].astype(int)]\n",
    "            matches2 = points2[:, matches[1, :].astype(int)]\n",
    "            print(f'Before: {matches1[:2, :].shape}, {matches2[:2, :].shape}')\n",
    "            \n",
    "            matches_RANSAC = tracker.nn_match_two_way_with_ransac(matches1[:2, :].T, matches2[:2, :].T, matches, max_reproj_error=2)\n",
    "            # print amount of TRUE in matches_RANSAC\n",
    "            print(f'After RANSAC: {np.sum(matches_RANSAC)}')\n",
    "            \n",
    "            # take elements from matches1 and matches2 where matches_RANSAC is TRUE\n",
    "            matches_RANSAC = matches_RANSAC.reshape(-1)\n",
    "            \n",
    "            matches1_RANSAC = matches1[:2, matches_RANSAC]\n",
    "            matches2_RANSAC = matches2[:2, matches_RANSAC]\n",
    "            print(f'{matches1_RANSAC.shape}, {matches2_RANSAC.shape}')\n",
    "\n",
    "            '''if j == i + 1:\n",
    "                # Create the \"output_points\" folder if it does not exist\n",
    "                output_folder = \"output_points\"\n",
    "                os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "                # Save points1, desc1, as files in the \"output_points\" folder\n",
    "                points1_file = os.path.join(output_folder, f\"img_{i}_points.txt\")\n",
    "                desc1_file = os.path.join(output_folder, f\"img_{i}_desc.txt\")\n",
    "\n",
    "                np.savetxt(points1_file, matches12)\n",
    "                np.savetxt(desc1_file, desc1)'''\n",
    "\n",
    "            # take the match score of the elements in matches_RANSAC\n",
    "            match_score = matches[2, matches_RANSAC]\n",
    "            # Create the subplot of the requested outputs\n",
    "            create_subplot(name, i, j, image1, image2, matches1_RANSAC, matches2_RANSAC, \\\n",
    "                           heatmap1, heatmap2, match_score)\n",
    "    print(\"Done!\")\n",
    "    # return points1, desc1, points2, desc2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 0 & 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 55), (2, 55)\n",
      "matches: (55,)\n",
      "After RANSAC: 11\n",
      "(2, 11), (2, 11)\n",
      "\n",
      "Image 0 & 2\n",
      "Before: (2, 28), (2, 28)\n",
      "matches: (28,)\n",
      "After RANSAC: 5\n",
      "(2, 5), (2, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 0 & 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 10), (2, 10)\n",
      "matches: (10,)\n",
      "After RANSAC: 4\n",
      "(2, 4), (2, 4)\n",
      "\n",
      "Image 0 & 4\n",
      "Before: (2, 19), (2, 19)\n",
      "matches: (19,)\n",
      "After RANSAC: 5\n",
      "(2, 5), (2, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 0 & 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 11), (2, 11)\n",
      "matches: (11,)\n",
      "After RANSAC: 4\n",
      "(2, 4), (2, 4)\n",
      "\n",
      "Image 0 & 6\n",
      "Before: (2, 10), (2, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (10,)\n",
      "After RANSAC: 3\n",
      "(2, 3), (2, 3)\n",
      "\n",
      "Image 0 & 7\n",
      "Before: (2, 10), (2, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (10,)\n",
      "After RANSAC: 5\n",
      "(2, 5), (2, 5)\n",
      "\n",
      "Image 0 & 8\n",
      "Before: (2, 245), (2, 245)\n",
      "matches: (245,)\n",
      "After RANSAC: 44\n",
      "(2, 44), (2, 44)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 0 & 9\n",
      "Before: (2, 188), (2, 188)\n",
      "matches: (188,)\n",
      "After RANSAC: 36\n",
      "(2, 36), (2, 36)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 0 & 10\n",
      "Before: (2, 17), (2, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (17,)\n",
      "After RANSAC: 6\n",
      "(2, 6), (2, 6)\n",
      "\n",
      "Image 0 & 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 18), (2, 18)\n",
      "matches: (18,)\n",
      "After RANSAC: 5\n",
      "(2, 5), (2, 5)\n",
      "\n",
      "Image 1 & 2\n",
      "Before: (2, 201), (2, 201)\n",
      "matches: (201,)\n",
      "After RANSAC: 45\n",
      "(2, 45), (2, 45)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 1 & 3\n",
      "Before: (2, 25), (2, 25)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (25,)\n",
      "After RANSAC: 6\n",
      "(2, 6), (2, 6)\n",
      "\n",
      "Image 1 & 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 15), (2, 15)\n",
      "matches: (15,)\n",
      "After RANSAC: 7\n",
      "(2, 7), (2, 7)\n",
      "\n",
      "Image 1 & 5\n",
      "Before: (2, 20), (2, 20)\n",
      "matches: (20,)\n",
      "After RANSAC: 4\n",
      "(2, 4), (2, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 1 & 6\n",
      "Before: (2, 2), (2, 2)\n",
      "ransac failed\n",
      "matches shape:  (3, 2)\n",
      "After RANSAC: 2\n",
      "(2, 2), (2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 1 & 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 21), (2, 21)\n",
      "matches: (21,)\n",
      "After RANSAC: 4\n",
      "(2, 4), (2, 4)\n",
      "\n",
      "Image 1 & 8\n",
      "Before: (2, 88), (2, 88)\n",
      "matches: (88,)\n",
      "After RANSAC: 41\n",
      "(2, 41), (2, 41)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 1 & 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 59), (2, 59)\n",
      "matches: (59,)\n",
      "After RANSAC: 17\n",
      "(2, 17), (2, 17)\n",
      "\n",
      "Image 1 & 10\n",
      "Before: (2, 10), (2, 10)\n",
      "matches: (10,)\n",
      "After RANSAC: 4\n",
      "(2, 4), (2, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 1 & 11\n",
      "Before: (2, 168), (2, 168)\n",
      "matches: (168,)\n",
      "After RANSAC: 38\n",
      "(2, 38), (2, 38)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 2 & 3\n",
      "Before: (2, 45), (2, 45)\n",
      "matches: (45,)\n",
      "After RANSAC: 10\n",
      "(2, 10), (2, 10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 2 & 4\n",
      "Before: (2, 13), (2, 13)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (13,)\n",
      "After RANSAC: 5\n",
      "(2, 5), (2, 5)\n",
      "\n",
      "Image 2 & 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 37), (2, 37)\n",
      "matches: (37,)\n",
      "After RANSAC: 9\n",
      "(2, 9), (2, 9)\n",
      "\n",
      "Image 2 & 6\n",
      "Before: (2, 2), (2, 2)\n",
      "ransac failed\n",
      "matches shape:  (3, 2)\n",
      "After RANSAC: 2\n",
      "(2, 2), (2, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 2 & 7\n",
      "Before: (2, 21), (2, 21)\n",
      "matches: (21,)\n",
      "After RANSAC: 6\n",
      "(2, 6), (2, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 2 & 8\n",
      "Before: (2, 99), (2, 99)\n",
      "matches: (99,)\n",
      "After RANSAC: 37\n",
      "(2, 37), (2, 37)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 2 & 9\n",
      "Before: (2, 98), (2, 98)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (98,)\n",
      "After RANSAC: 58\n",
      "(2, 58), (2, 58)\n",
      "\n",
      "Image 2 & 10\n",
      "Before: (2, 11), (2, 11)\n",
      "matches: (11,)\n",
      "After RANSAC: 6\n",
      "(2, 6), (2, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 2 & 11\n",
      "Before: (2, 399), (2, 399)\n",
      "matches: (399,)\n",
      "After RANSAC: 280\n",
      "(2, 280), (2, 280)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 3 & 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 22), (2, 22)\n",
      "matches: (22,)\n",
      "After RANSAC: 7\n",
      "(2, 7), (2, 7)\n",
      "\n",
      "Image 3 & 5\n",
      "Before: (2, 184), (2, 184)\n",
      "matches: (184,)\n",
      "After RANSAC: 82\n",
      "(2, 82), (2, 82)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 3 & 6\n",
      "Before: (2, 4), (2, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (4,)\n",
      "After RANSAC: 3\n",
      "(2, 3), (2, 3)\n",
      "\n",
      "Image 3 & 7\n",
      "Before: (2, 157), (2, 157)\n",
      "matches: (157,)\n",
      "After RANSAC: 72\n",
      "(2, 72), (2, 72)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 3 & 8\n",
      "Before: (2, 13), (2, 13)\n",
      "matches: (13,)\n",
      "After RANSAC: 4\n",
      "(2, 4), (2, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 3 & 9\n",
      "Before: (2, 8), (2, 8)\n",
      "matches: (8,)\n",
      "After RANSAC: 4\n",
      "(2, 4), (2, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 3 & 10\n",
      "Before: (2, 63), (2, 63)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (63,)\n",
      "After RANSAC: 18\n",
      "(2, 18), (2, 18)\n",
      "\n",
      "Image 3 & 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 24), (2, 24)\n",
      "matches: (24,)\n",
      "After RANSAC: 10\n",
      "(2, 10), (2, 10)\n",
      "\n",
      "Image 4 & 5\n",
      "Before: (2, 21), (2, 21)\n",
      "matches: (21,)\n",
      "After RANSAC: 4\n",
      "(2, 4), (2, 4)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 4 & 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 17), (2, 17)\n",
      "matches: (17,)\n",
      "After RANSAC: 5\n",
      "(2, 5), (2, 5)\n",
      "\n",
      "Image 4 & 7\n",
      "Before: (2, 19), (2, 19)\n",
      "matches: (19,)\n",
      "After RANSAC: 5\n",
      "(2, 5), (2, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 4 & 8\n",
      "Before: (2, 30), (2, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (30,)\n",
      "After RANSAC: 8\n",
      "(2, 8), (2, 8)\n",
      "\n",
      "Image 4 & 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 18), (2, 18)\n",
      "matches: (18,)\n",
      "After RANSAC: 6\n",
      "(2, 6), (2, 6)\n",
      "\n",
      "Image 4 & 10\n",
      "Before: (2, 132), (2, 132)\n",
      "matches: (132,)\n",
      "After RANSAC: 17\n",
      "(2, 17), (2, 17)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 4 & 11\n",
      "Before: (2, 9), (2, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (9,)\n",
      "After RANSAC: 3\n",
      "(2, 3), (2, 3)\n",
      "\n",
      "Image 5 & 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 4), (2, 4)\n",
      "matches: (4,)\n",
      "After RANSAC: 3\n",
      "(2, 3), (2, 3)\n",
      "\n",
      "Image 5 & 7\n",
      "Before: (2, 187), (2, 187)\n",
      "matches: (187,)\n",
      "After RANSAC: 96\n",
      "(2, 96), (2, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 5 & 8\n",
      "Before: (2, 12), (2, 12)\n",
      "matches: (12,)\n",
      "After RANSAC: 5\n",
      "(2, 5), (2, 5)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 5 & 9\n",
      "Before: (2, 6), (2, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (6,)\n",
      "After RANSAC: 4\n",
      "(2, 4), (2, 4)\n",
      "\n",
      "Image 5 & 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 72), (2, 72)\n",
      "matches: (72,)\n",
      "After RANSAC: 12\n",
      "(2, 12), (2, 12)\n",
      "\n",
      "Image 5 & 11\n",
      "Before: (2, 24), (2, 24)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (24,)\n",
      "After RANSAC: 10\n",
      "(2, 10), (2, 10)\n",
      "\n",
      "Image 6 & 7\n",
      "Before: (2, 5), (2, 5)\n",
      "matches: (5,)\n",
      "After RANSAC: 3\n",
      "(2, 3), (2, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 6 & 8\n",
      "Before: (2, 8), (2, 8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (8,)\n",
      "After RANSAC: 3\n",
      "(2, 3), (2, 3)\n",
      "\n",
      "Image 6 & 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 7), (2, 7)\n",
      "matches: (7,)\n",
      "After RANSAC: 3\n",
      "(2, 3), (2, 3)\n",
      "\n",
      "Image 6 & 10\n",
      "Before: (2, 27), (2, 27)\n",
      "matches: (27,)\n",
      "After RANSAC: 9\n",
      "(2, 9), (2, 9)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 6 & 11\n",
      "Before: (2, 3), (2, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (3,)\n",
      "After RANSAC: 2\n",
      "(2, 2), (2, 2)\n",
      "\n",
      "Image 7 & 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 10), (2, 10)\n",
      "matches: (10,)\n",
      "After RANSAC: 4\n",
      "(2, 4), (2, 4)\n",
      "\n",
      "Image 7 & 9\n",
      "Before: (2, 5), (2, 5)\n",
      "matches: (5,)\n",
      "After RANSAC: 3\n",
      "(2, 3), (2, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 7 & 10\n",
      "Before: (2, 71), (2, 71)\n",
      "matches: (71,)\n",
      "After RANSAC: 14\n",
      "(2, 14), (2, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 7 & 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 16), (2, 16)\n",
      "matches: (16,)\n",
      "After RANSAC: 7\n",
      "(2, 7), (2, 7)\n",
      "\n",
      "Image 8 & 9\n",
      "Before: (2, 391), (2, 391)\n",
      "matches: (391,)\n",
      "After RANSAC: 204\n",
      "(2, 204), (2, 204)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 8 & 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before: (2, 19), (2, 19)\n",
      "matches: (19,)\n",
      "After RANSAC: 6\n",
      "(2, 6), (2, 6)\n",
      "\n",
      "Image 8 & 11\n",
      "Before: (2, 69), (2, 69)\n",
      "matches: (69,)\n",
      "After RANSAC: 18\n",
      "(2, 18), (2, 18)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 9 & 10\n",
      "Before: (2, 14), (2, 14)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "matches: (14,)\n",
      "After RANSAC: 6\n",
      "(2, 6), (2, 6)\n",
      "\n",
      "Image 9 & 11\n",
      "Before: (2, 67), (2, 67)\n",
      "matches: (67,)\n",
      "After RANSAC: 19\n",
      "(2, 19), (2, 19)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Image 10 & 11\n",
      "Before: (2, 9), (2, 9)\n",
      "matches: (9,)\n",
      "After RANSAC: 3\n",
      "(2, 3), (2, 3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done!\n"
     ]
    }
   ],
   "source": [
    "# Set your file path and other arguments here\n",
    "file_path = \"../Dataset/Dataset-processed/05-05-2560/3084442-L/b1\"\n",
    "\n",
    "main(file_path, '05-05-2560_3084442-L_b1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
