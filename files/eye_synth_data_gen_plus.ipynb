{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notice\n",
    "Actually this file might not be needed as heatmaps can be created on-the-fly using SuperPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5040, 9)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Directory</th>\n",
       "      <th>Source image</th>\n",
       "      <th>Source ROI</th>\n",
       "      <th>Target image</th>\n",
       "      <th>Target ROI</th>\n",
       "      <th>training</th>\n",
       "      <th>Warped target images</th>\n",
       "      <th>Warped target ROI</th>\n",
       "      <th>Execution time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "      <td>2011248_20161215__L_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "      <td>2011248_20161215__L_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lb</td>\n",
       "      <td>2011248_20161215__L_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Directory  \\\n",
       "0  Dataset/Dataset-processed/15-12-2559/2011248/Lb   \n",
       "1  Dataset/Dataset-processed/15-12-2559/2011248/Lb   \n",
       "2  Dataset/Dataset-processed/15-12-2559/2011248/Lb   \n",
       "3  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "4  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "\n",
       "                 Source image  Source ROI                Target image  \\\n",
       "0  2011248_20161215__L_b2.jpg         NaN  2011248_20161215__L_b1.jpg   \n",
       "1  2011248_20161215__L_b2.jpg         NaN  2011248_20161215__L_b3.jpg   \n",
       "2  2011248_20161215__L_b1.jpg         NaN  2011248_20161215__L_b3.jpg   \n",
       "3  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c1.jpg   \n",
       "4  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "\n",
       "   Target ROI  training  Warped target images  Warped target ROI  \\\n",
       "0         NaN         1                   NaN                NaN   \n",
       "1         NaN         1                   NaN                NaN   \n",
       "2         NaN         1                   NaN                NaN   \n",
       "3         NaN         0                   NaN                NaN   \n",
       "4         NaN         0                   NaN                NaN   \n",
       "\n",
       "   Execution time  \n",
       "0             NaN  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read the file 'dataset_reg_pair_filled.csv' and generate synthetic data\n",
    "# first read the file, then make a list of the source training images\n",
    "# then for each image, generate 10 synthetic images with random affine transformation\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "import math\n",
    "import csv\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "# read the file\n",
    "df = pd.read_csv('dataset_reg_pair_filled.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47849/2276967894.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_train['image_path'] = df_train['Directory'] + '/' + df_train['Source image']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Directory</th>\n",
       "      <th>Source image</th>\n",
       "      <th>Source ROI</th>\n",
       "      <th>Target image</th>\n",
       "      <th>Target ROI</th>\n",
       "      <th>training</th>\n",
       "      <th>Warped target images</th>\n",
       "      <th>Warped target ROI</th>\n",
       "      <th>Execution time</th>\n",
       "      <th>image_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>2011248_20161215__L_c2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Lc</td>\n",
       "      <td>2011248_20161215__L_c1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__L_c3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/L...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Rb</td>\n",
       "      <td>2011248_20161215__R_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__R_b3.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/Rb</td>\n",
       "      <td>2011248_20161215__R_b2.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2011248_20161215__R_b1.jpg</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Dataset/Dataset-processed/15-12-2559/2011248/R...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         Directory  \\\n",
       "3  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "4  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "5  Dataset/Dataset-processed/15-12-2559/2011248/Lc   \n",
       "6  Dataset/Dataset-processed/15-12-2559/2011248/Rb   \n",
       "7  Dataset/Dataset-processed/15-12-2559/2011248/Rb   \n",
       "\n",
       "                 Source image  Source ROI                Target image  \\\n",
       "3  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c1.jpg   \n",
       "4  2011248_20161215__L_c2.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "5  2011248_20161215__L_c1.jpg         NaN  2011248_20161215__L_c3.jpg   \n",
       "6  2011248_20161215__R_b2.jpg         NaN  2011248_20161215__R_b3.jpg   \n",
       "7  2011248_20161215__R_b2.jpg         NaN  2011248_20161215__R_b1.jpg   \n",
       "\n",
       "   Target ROI  training  Warped target images  Warped target ROI  \\\n",
       "3         NaN         0                   NaN                NaN   \n",
       "4         NaN         0                   NaN                NaN   \n",
       "5         NaN         0                   NaN                NaN   \n",
       "6         NaN         0                   NaN                NaN   \n",
       "7         NaN         0                   NaN                NaN   \n",
       "\n",
       "   Execution time                                         image_path  \n",
       "3             NaN  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "4             NaN  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "5             NaN  Dataset/Dataset-processed/15-12-2559/2011248/L...  \n",
       "6             NaN  Dataset/Dataset-processed/15-12-2559/2011248/R...  \n",
       "7             NaN  Dataset/Dataset-processed/15-12-2559/2011248/R...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make a list of the unique source training images that has 'training' = 0\n",
    "# each image path consists of image directory, image name\n",
    "\n",
    "df_train = df[df['training'] == 0]\n",
    "\n",
    "# create a new df consists of image directory and image name concatenated\n",
    "df_train['image_path'] = df_train['Directory'] + '/' + df_train['Source image']\n",
    "df_train.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4132, 10)\n",
      "920\n",
      "Dataset/Dataset-processed/15-12-2559/2011248/Lc/2011248_20161215__L_c2.jpg\n"
     ]
    }
   ],
   "source": [
    "print(df_train.shape)\n",
    "# make a list of the unique values in the column 'image_path'\n",
    "\n",
    "image_list = df_train['image_path'].unique()\n",
    "print(len(image_list))\n",
    "print(image_list[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define parameters\n",
    "image_size = (512, 512)  # Size of the images\n",
    "output_dir = \"Dataset/synthetic_eye_dataset_train\"  # Output directory\n",
    "plot_dir = \"Dataset/synthetic_eye_dataset_train/plot\"\n",
    "max_translation = 20  # Maximum translation in pixels\n",
    "max_rotation = 10  # Maximum rotation in degrees\n",
    "max_shear = 5  # Maximum shear in degrees\n",
    "max_scale = 1.1  # Maximum scale factor\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SuperPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SuperPointNet(torch.nn.Module):\n",
    "  \"\"\" Pytorch definition of SuperPoint Network. \"\"\"\n",
    "  def __init__(self):\n",
    "    super(SuperPointNet, self).__init__()\n",
    "    self.relu = torch.nn.ReLU(inplace=True)\n",
    "    self.pool = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "    c1, c2, c3, c4, c5, d1 = 64, 64, 128, 128, 256, 256\n",
    "    # Shared Encoder.\n",
    "    self.conv1a = torch.nn.Conv2d(1, c1, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv1b = torch.nn.Conv2d(c1, c1, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv2a = torch.nn.Conv2d(c1, c2, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv2b = torch.nn.Conv2d(c2, c2, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv3a = torch.nn.Conv2d(c2, c3, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv3b = torch.nn.Conv2d(c3, c3, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv4a = torch.nn.Conv2d(c3, c4, kernel_size=3, stride=1, padding=1)\n",
    "    self.conv4b = torch.nn.Conv2d(c4, c4, kernel_size=3, stride=1, padding=1)\n",
    "    # Detector Head.\n",
    "    self.convPa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
    "    self.convPb = torch.nn.Conv2d(c5, 65, kernel_size=1, stride=1, padding=0)\n",
    "    # Descriptor Head.\n",
    "    self.convDa = torch.nn.Conv2d(c4, c5, kernel_size=3, stride=1, padding=1)\n",
    "    self.convDb = torch.nn.Conv2d(c5, d1, kernel_size=1, stride=1, padding=0)\n",
    "\n",
    "  def forward(self, x):\n",
    "    \"\"\" Forward pass that jointly computes unprocessed point and descriptor\n",
    "    tensors.\n",
    "    Input\n",
    "      x: Image pytorch tensor shaped N x 1 x H x W.\n",
    "    Output\n",
    "      semi: Output point pytorch tensor shaped N x 65 x H/8 x W/8.\n",
    "      desc: Output descriptor pytorch tensor shaped N x 256 x H/8 x W/8.\n",
    "    \"\"\"\n",
    "    # Shared Encoder.\n",
    "    x = self.relu(self.conv1a(x))\n",
    "    x = self.relu(self.conv1b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv2a(x))\n",
    "    x = self.relu(self.conv2b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv3a(x))\n",
    "    x = self.relu(self.conv3b(x))\n",
    "    x = self.pool(x)\n",
    "    x = self.relu(self.conv4a(x))\n",
    "    x = self.relu(self.conv4b(x))\n",
    "    # Detector Head.\n",
    "    cPa = self.relu(self.convPa(x))\n",
    "    semi = self.convPb(cPa)\n",
    "    # Descriptor Head.\n",
    "    cDa = self.relu(self.convDa(x))\n",
    "    desc = self.convDb(cDa)\n",
    "    dn = torch.norm(desc, p=2, dim=1) # Compute the norm.\n",
    "    desc = desc.div(torch.unsqueeze(dn, 1)) # Divide by norm to normalize.\n",
    "    return semi, desc\n",
    "\n",
    "\n",
    "class SuperPointFrontend(object):\n",
    "  \"\"\" Wrapper around pytorch net to help with pre and post image processing. \"\"\"\n",
    "  def __init__(self, weights_path, nms_dist, conf_thresh, nn_thresh,\n",
    "               cuda=False):\n",
    "    self.name = 'SuperPoint'\n",
    "    self.cuda = cuda\n",
    "    self.nms_dist = nms_dist\n",
    "    self.conf_thresh = conf_thresh\n",
    "    self.nn_thresh = nn_thresh # L2 descriptor distance for good match.\n",
    "    self.cell = 8 # Size of each output cell. Keep this fixed.\n",
    "    self.border_remove = 4 # Remove points this close to the border.\n",
    "\n",
    "    # Load the network in inference mode.\n",
    "    self.net = SuperPointNet()\n",
    "    if cuda:\n",
    "      # Train on GPU, deploy on GPU.\n",
    "      self.net.load_state_dict(torch.load(weights_path))\n",
    "      self.net = self.net.cuda()\n",
    "    else:\n",
    "      # Train on GPU, deploy on CPU.\n",
    "      self.net.load_state_dict(torch.load(weights_path,\n",
    "                               map_location=lambda storage, loc: storage))\n",
    "    self.net.eval()\n",
    "\n",
    "  def nms_fast(self, in_corners, H, W, dist_thresh):\n",
    "    \"\"\"\n",
    "    Run a faster approximate Non-Max-Suppression on numpy corners shaped:\n",
    "      3xN [x_i,y_i,conf_i]^T\n",
    "  \n",
    "    Algo summary: Create a grid sized HxW. Assign each corner location a 1, rest\n",
    "    are zeros. Iterate through all the 1's and convert them either to -1 or 0.\n",
    "    Suppress points by setting nearby values to 0.\n",
    "  \n",
    "    Grid Value Legend:\n",
    "    -1 : Kept.\n",
    "     0 : Empty or suppressed.\n",
    "     1 : To be processed (converted to either kept or supressed).\n",
    "  \n",
    "    NOTE: The NMS first rounds points to integers, so NMS distance might not\n",
    "    be exactly dist_thresh. It also assumes points are within image boundaries.\n",
    "  \n",
    "    Inputs\n",
    "      in_corners - 3xN numpy array with corners [x_i, y_i, confidence_i]^T.\n",
    "      H - Image height.\n",
    "      W - Image width.\n",
    "      dist_thresh - Distance to suppress, measured as an infinty norm distance.\n",
    "    Returns\n",
    "      nmsed_corners - 3xN numpy matrix with surviving corners.\n",
    "      nmsed_inds - N length numpy vector with surviving corner indices.\n",
    "    \"\"\"\n",
    "    grid = np.zeros((H, W)).astype(int) # Track NMS data.\n",
    "    inds = np.zeros((H, W)).astype(int) # Store indices of points.\n",
    "    # Sort by confidence and round to nearest int.\n",
    "    inds1 = np.argsort(-in_corners[2,:])\n",
    "    corners = in_corners[:,inds1]\n",
    "    rcorners = corners[:2,:].round().astype(int) # Rounded corners.\n",
    "    # Check for edge case of 0 or 1 corners.\n",
    "    if rcorners.shape[1] == 0:\n",
    "      return np.zeros((3,0)).astype(int), np.zeros(0).astype(int)\n",
    "    if rcorners.shape[1] == 1:\n",
    "      out = np.vstack((rcorners, in_corners[2])).reshape(3,1)\n",
    "      return out, np.zeros((1)).astype(int)\n",
    "    # Initialize the grid.\n",
    "    for i, rc in enumerate(rcorners.T):\n",
    "      grid[rcorners[1,i], rcorners[0,i]] = 1\n",
    "      inds[rcorners[1,i], rcorners[0,i]] = i\n",
    "    # Pad the border of the grid, so that we can NMS points near the border.\n",
    "    pad = dist_thresh\n",
    "    grid = np.pad(grid, ((pad,pad), (pad,pad)), mode='constant')\n",
    "    # Iterate through points, highest to lowest conf, suppress neighborhood.\n",
    "    count = 0\n",
    "    for i, rc in enumerate(rcorners.T):\n",
    "      # Account for top and left padding.\n",
    "      pt = (rc[0]+pad, rc[1]+pad)\n",
    "      if grid[pt[1], pt[0]] == 1: # If not yet suppressed.\n",
    "        grid[pt[1]-pad:pt[1]+pad+1, pt[0]-pad:pt[0]+pad+1] = 0\n",
    "        grid[pt[1], pt[0]] = -1\n",
    "        count += 1\n",
    "    # Get all surviving -1's and return sorted array of remaining corners.\n",
    "    keepy, keepx = np.where(grid==-1)\n",
    "    keepy, keepx = keepy - pad, keepx - pad\n",
    "    inds_keep = inds[keepy, keepx]\n",
    "    out = corners[:, inds_keep]\n",
    "    values = out[-1, :]\n",
    "    inds2 = np.argsort(-values)\n",
    "    out = out[:, inds2]\n",
    "    out_inds = inds1[inds_keep[inds2]]\n",
    "    return out, out_inds\n",
    "\n",
    "  def run(self, img):\n",
    "    \"\"\" Process a numpy image to extract points and descriptors.\n",
    "    Input\n",
    "      img - HxW numpy float32 input image in range [0,1].\n",
    "    Output\n",
    "      corners - 3xN numpy array with corners [x_i, y_i, confidence_i]^T.\n",
    "      desc - 256xN numpy array of corresponding unit normalized descriptors.\n",
    "      heatmap - HxW numpy heatmap in range [0,1] of point confidences.\n",
    "      \"\"\"\n",
    "    assert img.ndim == 2, 'Image must be grayscale.'\n",
    "    assert img.dtype == np.float32, 'Image must be float32.'\n",
    "    H, W = img.shape[0], img.shape[1]\n",
    "    inp = img.copy()\n",
    "    inp = (inp.reshape(1, H, W))\n",
    "    inp = torch.from_numpy(inp)\n",
    "    inp = torch.autograd.Variable(inp).view(1, 1, H, W)\n",
    "    if self.cuda:\n",
    "      inp = inp.cuda()\n",
    "    # Forward pass of network.\n",
    "    outs = self.net.forward(inp)\n",
    "    semi, coarse_desc = outs[0], outs[1]\n",
    "    # Convert pytorch -> numpy.\n",
    "    semi = semi.data.cpu().numpy().squeeze()\n",
    "    # --- Process points.\n",
    "    dense = np.exp(semi) # Softmax.\n",
    "    dense = dense / (np.sum(dense, axis=0)+.00001) # Should sum to 1.\n",
    "    # Remove dustbin.\n",
    "    nodust = dense[:-1, :, :]\n",
    "    # Reshape to get full resolution heatmap.\n",
    "    Hc = int(H / self.cell)\n",
    "    Wc = int(W / self.cell)\n",
    "    nodust = nodust.transpose(1, 2, 0)\n",
    "    heatmap = np.reshape(nodust, [Hc, Wc, self.cell, self.cell])\n",
    "    heatmap = np.transpose(heatmap, [0, 2, 1, 3])\n",
    "    heatmap = np.reshape(heatmap, [Hc*self.cell, Wc*self.cell])\n",
    "    xs, ys = np.where(heatmap >= self.conf_thresh) # Confidence threshold.\n",
    "    if len(xs) == 0:\n",
    "      return np.zeros((3, 0)), None, None\n",
    "    pts = np.zeros((3, len(xs))) # Populate point data sized 3xN.\n",
    "    pts[0, :] = ys\n",
    "    pts[1, :] = xs\n",
    "    pts[2, :] = heatmap[xs, ys]\n",
    "    pts, _ = self.nms_fast(pts, H, W, dist_thresh=self.nms_dist) # Apply NMS.\n",
    "    inds = np.argsort(pts[2,:])\n",
    "    pts = pts[:,inds[::-1]] # Sort by confidence.\n",
    "    # Remove points along border.\n",
    "    bord = self.border_remove\n",
    "    toremoveW = np.logical_or(pts[0, :] < bord, pts[0, :] >= (W-bord))\n",
    "    toremoveH = np.logical_or(pts[1, :] < bord, pts[1, :] >= (H-bord))\n",
    "    toremove = np.logical_or(toremoveW, toremoveH)\n",
    "    pts = pts[:, ~toremove]\n",
    "    # --- Process descriptor.\n",
    "    D = coarse_desc.shape[1]\n",
    "    if pts.shape[1] == 0:\n",
    "      desc = np.zeros((D, 0))\n",
    "    else:\n",
    "      # Interpolate into descriptor map using 2D point locations.\n",
    "      samp_pts = torch.from_numpy(pts[:2, :].copy())\n",
    "      samp_pts[0, :] = (samp_pts[0, :] / (float(W)/2.)) - 1.\n",
    "      samp_pts[1, :] = (samp_pts[1, :] / (float(H)/2.)) - 1.\n",
    "      samp_pts = samp_pts.transpose(0, 1).contiguous()\n",
    "      samp_pts = samp_pts.view(1, 1, -1, 2)\n",
    "      samp_pts = samp_pts.float()\n",
    "      if self.cuda:\n",
    "        samp_pts = samp_pts.cuda()\n",
    "      desc = torch.nn.functional.grid_sample(coarse_desc, samp_pts, align_corners=True)\n",
    "      desc = desc.data.cpu().numpy().reshape(D, -1)\n",
    "      desc /= np.linalg.norm(desc, axis=0)[np.newaxis, :]\n",
    "    return pts, desc, heatmap\n",
    "\n",
    "\n",
    "class PointTracker(object):\n",
    "  \"\"\" Class to manage a fixed memory of points and descriptors that enables\n",
    "  sparse optical flow point tracking.\n",
    "\n",
    "  Internally, the tracker stores a 'tracks' matrix sized M x (2+L), of M\n",
    "  tracks with maximum length L, where each row corresponds to:\n",
    "  row_m = [track_id_m, avg_desc_score_m, point_id_0_m, ..., point_id_L-1_m].\n",
    "  \"\"\"\n",
    "\n",
    "  def __init__(self, max_length, nn_thresh):\n",
    "    if max_length < 2:\n",
    "      raise ValueError('max_length must be greater than or equal to 2.')\n",
    "    self.maxl = max_length\n",
    "    self.nn_thresh = nn_thresh\n",
    "    self.all_pts = []\n",
    "    for n in range(self.maxl):\n",
    "      self.all_pts.append(np.zeros((2, 0)))\n",
    "    self.last_desc = None\n",
    "    self.tracks = np.zeros((0, self.maxl+2))\n",
    "    self.track_count = 0\n",
    "    self.max_score = 9999\n",
    "\n",
    "  def nn_match_two_way(self, desc1, desc2, nn_thresh):\n",
    "    \"\"\"\n",
    "    Performs two-way nearest neighbor matching of two sets of descriptors, such\n",
    "    that the NN match from descriptor A->B must equal the NN match from B->A.\n",
    "\n",
    "    Inputs:\n",
    "      desc1 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      desc2 - NxM numpy matrix of N corresponding M-dimensional descriptors.\n",
    "      nn_thresh - Optional descriptor distance below which is a good match.\n",
    "\n",
    "    Returns:\n",
    "      matches - 3xL numpy array, of L matches, where L <= N and each column i is\n",
    "                a match of two descriptors, d_i in image 1 and d_j' in image 2:\n",
    "                [d_i index, d_j' index, match_score]^T\n",
    "    \"\"\"\n",
    "    assert desc1.shape[0] == desc2.shape[0]\n",
    "    if desc1.shape[1] == 0 or desc2.shape[1] == 0:\n",
    "      return np.zeros((3, 0))\n",
    "    if nn_thresh < 0.0:\n",
    "      raise ValueError('\\'nn_thresh\\' should be non-negative')\n",
    "    # Compute L2 distance. Easy since vectors are unit normalized.\n",
    "    dmat = np.dot(desc1.T, desc2)\n",
    "    dmat = np.sqrt(2-2*np.clip(dmat, -1, 1))\n",
    "    # Get NN indices and scores.\n",
    "    idx = np.argmin(dmat, axis=1)\n",
    "    scores = dmat[np.arange(dmat.shape[0]), idx]\n",
    "    # Threshold the NN matches.  <<< ======================= this threshold is not good\n",
    "    keep = scores < nn_thresh\n",
    "    # Check if nearest neighbor goes both directions and keep those.\n",
    "    idx2 = np.argmin(dmat, axis=0)\n",
    "    keep_bi = np.arange(len(idx)) == idx2[idx]\n",
    "    keep = np.logical_and(keep, keep_bi)\n",
    "    idx = idx[keep]\n",
    "    scores = scores[keep]\n",
    "    # Get the surviving point indices.\n",
    "    m_idx1 = np.arange(desc1.shape[1])[keep]\n",
    "    m_idx2 = idx\n",
    "    # Populate the final 3xN match data structure.\n",
    "    matches = np.zeros((3, int(keep.sum())))\n",
    "    matches[0, :] = m_idx1\n",
    "    matches[1, :] = m_idx2\n",
    "    matches[2, :] = scores\n",
    "    return matches\n",
    "  \n",
    "  def ransac(self, points1, points2, matches, max_reproj_error=5.0):  # <<=========================================== TODO Here is the RANSAC\n",
    "    '''find matching points between two images using RANSAC'''\n",
    "    \n",
    "    # estimate affine transform model using all coordinates\n",
    "    model = AffineTransform()\n",
    "    model.estimate(points1, points2)\n",
    "\n",
    "    # try min_samples = 3, if fail, try min_samples = 2\n",
    "    try:\n",
    "      # Find the best fundamental matrix using RANSAC\n",
    "      best_model, best_inliers = ransac((points1, points2),\n",
    "                                        AffineTransform, min_samples=3,\n",
    "                                        residual_threshold=max_reproj_error, max_trials=100)\n",
    "    except:\n",
    "      try:\n",
    "        best_model, best_inliers = ransac((points1, points2),\n",
    "                                          AffineTransform, min_samples=2,\n",
    "                                          residual_threshold=max_reproj_error, max_trials=100)\n",
    "        \n",
    "      except:\n",
    "        # if ransac failed, return an array of TRUE with the original matches shape\n",
    "        print('ransac failed')\n",
    "        print('matches shape: ', matches.shape)\n",
    "        return np.ones((matches.shape[1])).astype(bool)\n",
    "    \n",
    "    # the inliners are the matching points\n",
    "    matches = np.array(best_inliers).T\n",
    "\n",
    "    # print(f'matches: {matches.shape}')\n",
    "    return matches\n",
    "\n",
    "  def get_offsets(self):\n",
    "    \"\"\" Iterate through list of points and accumulate an offset value. Used to\n",
    "    index the global point IDs into the list of points.\n",
    "\n",
    "    Returns\n",
    "      offsets - N length array with integer offset locations.\n",
    "    \"\"\"\n",
    "    # Compute id offsets.\n",
    "    offsets = []\n",
    "    offsets.append(0)\n",
    "    for i in range(len(self.all_pts)-1): # Skip last camera size, not needed.\n",
    "      offsets.append(self.all_pts[i].shape[1])\n",
    "    offsets = np.array(offsets)\n",
    "    offsets = np.cumsum(offsets)\n",
    "    return offsets\n",
    "\n",
    "  def update(self, pts, desc):\n",
    "    \"\"\" Add a new set of point and descriptor observations to the tracker.\n",
    "\n",
    "    Inputs\n",
    "      pts - 3xN numpy array of 2D point observations.\n",
    "      desc - DxN numpy array of corresponding D dimensional descriptors.\n",
    "    \"\"\"\n",
    "    if pts is None or desc is None:\n",
    "      print('PointTracker: Warning, no points were added to tracker.')\n",
    "      return\n",
    "    assert pts.shape[1] == desc.shape[1]\n",
    "    # Initialize last_desc.\n",
    "    if self.last_desc is None:\n",
    "      self.last_desc = np.zeros((desc.shape[0], 0))\n",
    "    # Remove oldest points, store its size to update ids later.\n",
    "    remove_size = self.all_pts[0].shape[1]\n",
    "    self.all_pts.pop(0)\n",
    "    self.all_pts.append(pts)\n",
    "    # Remove oldest point in track.\n",
    "    self.tracks = np.delete(self.tracks, 2, axis=1)\n",
    "    # Update track offsets.\n",
    "    for i in range(2, self.tracks.shape[1]):\n",
    "      self.tracks[:, i] -= remove_size\n",
    "    self.tracks[:, 2:][self.tracks[:, 2:] < -1] = -1\n",
    "    offsets = self.get_offsets()\n",
    "    # Add a new -1 column.\n",
    "    self.tracks = np.hstack((self.tracks, -1*np.ones((self.tracks.shape[0], 1))))\n",
    "    # Try to append to existing tracks.\n",
    "    matched = np.zeros((pts.shape[1])).astype(bool)\n",
    "    matches = self.nn_match_two_way(self.last_desc, desc, self.nn_thresh)\n",
    "    for match in matches.T:\n",
    "      # Add a new point to it's matched track.\n",
    "      id1 = int(match[0]) + offsets[-2]\n",
    "      id2 = int(match[1]) + offsets[-1]\n",
    "      found = np.argwhere(self.tracks[:, -2] == id1)\n",
    "      if found.shape[0] > 0:\n",
    "        matched[int(match[1])] = True\n",
    "        row = int(found)\n",
    "        self.tracks[row, -1] = id2\n",
    "        if self.tracks[row, 1] == self.max_score:\n",
    "          # Initialize track score.\n",
    "          self.tracks[row, 1] = match[2]\n",
    "        else:\n",
    "          # Update track score with running average.\n",
    "          # NOTE(dd): this running average can contain scores from old matches\n",
    "          #           not contained in last max_length track points.\n",
    "          track_len = (self.tracks[row, 2:] != -1).sum() - 1.\n",
    "          frac = 1. / float(track_len)\n",
    "          self.tracks[row, 1] = (1.-frac)*self.tracks[row, 1] + frac*match[2]\n",
    "    # Add unmatched tracks.\n",
    "    new_ids = np.arange(pts.shape[1]) + offsets[-1]\n",
    "    new_ids = new_ids[~matched]\n",
    "    new_tracks = -1*np.ones((new_ids.shape[0], self.maxl + 2))\n",
    "    new_tracks[:, -1] = new_ids\n",
    "    new_num = new_ids.shape[0]\n",
    "    new_trackids = self.track_count + np.arange(new_num)\n",
    "    new_tracks[:, 0] = new_trackids\n",
    "    new_tracks[:, 1] = self.max_score*np.ones(new_ids.shape[0])\n",
    "    self.tracks = np.vstack((self.tracks, new_tracks))\n",
    "    self.track_count += new_num # Update the track count.\n",
    "    # Remove empty tracks.\n",
    "    keep_rows = np.any(self.tracks[:, 2:] >= 0, axis=1)\n",
    "    self.tracks = self.tracks[keep_rows, :]\n",
    "    # Store the last descriptors.\n",
    "    self.last_desc = desc.copy()\n",
    "    return\n",
    "\n",
    "  def get_tracks(self, min_length):\n",
    "    \"\"\" Retrieve point tracks of a given minimum length.\n",
    "    Input\n",
    "      min_length - integer >= 1 with minimum track length\n",
    "    Output\n",
    "      returned_tracks - M x (2+L) sized matrix storing track indices, where\n",
    "        M is the number of tracks and L is the maximum track length.\n",
    "    \"\"\"\n",
    "    if min_length < 1:\n",
    "      raise ValueError('\\'min_length\\' too small.')\n",
    "    valid = np.ones((self.tracks.shape[0])).astype(bool)\n",
    "    good_len = np.sum(self.tracks[:, 2:] != -1, axis=1) >= min_length\n",
    "    # Remove tracks which do not have an observation in most recent frame.\n",
    "    not_headless = (self.tracks[:, -1] != -1)\n",
    "    keepers = np.logical_and.reduce((valid, good_len, not_headless))\n",
    "    returned_tracks = self.tracks[keepers, :].copy()\n",
    "    return returned_tracks\n",
    "\n",
    "  def draw_tracks(self, out, tracks):\n",
    "    \"\"\" Visualize tracks all overlayed on a single image.\n",
    "    Inputs\n",
    "      out - numpy uint8 image sized HxWx3 upon which tracks are overlayed.\n",
    "      tracks - M x (2+L) sized matrix storing track info.\n",
    "    \"\"\"\n",
    "    # Store the number of points per camera.\n",
    "    pts_mem = self.all_pts\n",
    "    N = len(pts_mem) # Number of cameras/images.\n",
    "    # Get offset ids needed to reference into pts_mem.\n",
    "    offsets = self.get_offsets()\n",
    "    # Width of track and point circles to be drawn.\n",
    "    stroke = 1\n",
    "    # Iterate through each track and draw it.\n",
    "    for track in tracks:\n",
    "      clr = myjet[int(np.clip(np.floor(track[1]*10), 0, 9)), :]*255\n",
    "      for i in range(N-1):\n",
    "        if track[i+2] == -1 or track[i+3] == -1:\n",
    "          continue\n",
    "        offset1 = offsets[i]\n",
    "        offset2 = offsets[i+1]\n",
    "        idx1 = int(track[i+2]-offset1)\n",
    "        idx2 = int(track[i+3]-offset2)\n",
    "        pt1 = pts_mem[i][:2, idx1]\n",
    "        pt2 = pts_mem[i+1][:2, idx2]\n",
    "        p1 = (int(round(pt1[0])), int(round(pt1[1])))\n",
    "        p2 = (int(round(pt2[0])), int(round(pt2[1])))\n",
    "        cv2.line(out, p1, p2, clr, thickness=stroke, lineType=16)\n",
    "        # Draw end points of each track.\n",
    "        if i == N-2:\n",
    "          clr2 = (255, 0, 0)\n",
    "          cv2.circle(out, p2, stroke, clr2, -1, lineType=16)\n",
    "\n",
    "  def read_image(self, impath, img_size):\n",
    "    \"\"\" Read image as grayscale and resize to img_size.\n",
    "    Inputs\n",
    "      impath: Path to input image.\n",
    "      img_size: (W, H) tuple specifying resize size.\n",
    "    Returns\n",
    "      grayim: float32 numpy array sized H x W with values in range [0, 1].\n",
    "    \"\"\"\n",
    "    grayim = cv2.imread(impath, 0)\n",
    "    if grayim is None:\n",
    "      raise Exception('Error reading image %s' % impath)\n",
    "    # Image is resized via opencv.\n",
    "    interp = cv2.INTER_AREA\n",
    "    grayim = cv2.resize(grayim, (img_size[1], img_size[0]), interpolation=interp)\n",
    "    grayim = (grayim.astype('float32') / 255.)\n",
    "    return grayim\n",
    "\n",
    "  def next_frame(self):\n",
    "    \"\"\" Return the next frame, and increment internal counter.\n",
    "    Returns\n",
    "       image: Next H x W image.\n",
    "       status: True or False depending whether image was loaded.\n",
    "    \"\"\"\n",
    "    if self.i == self.maxlen:\n",
    "      return (None, False)\n",
    "    if self.camera:\n",
    "      ret, input_image = self.cap.read()\n",
    "      if ret is False:\n",
    "        print('VideoStreamer: Cannot get image from camera (maybe bad --camid?)')\n",
    "        return (None, False)\n",
    "      if self.video_file:\n",
    "        self.cap.set(cv2.CAP_PROP_POS_FRAMES, self.listing[self.i])\n",
    "      input_image = cv2.resize(input_image, (self.sizer[1], self.sizer[0]),\n",
    "                               interpolation=cv2.INTER_AREA)\n",
    "      input_image = cv2.cvtColor(input_image, cv2.COLOR_RGB2GRAY)\n",
    "      input_image = input_image.astype('float')/255.0\n",
    "    else:\n",
    "      image_file = self.listing[self.i]\n",
    "      input_image = self.read_image(image_file, self.sizer)\n",
    "    # Increment internal counter.\n",
    "    self.i = self.i + 1\n",
    "    input_image = input_image.astype('float32')\n",
    "    return (input_image, True)\n",
    "  \n",
    "# load images\n",
    "def load_image(img_path, img_size=(512, 512)):\n",
    "    grayim = cv2.imread(img_path, 0)\n",
    "    interp = cv2.INTER_AREA\n",
    "    grayim = cv2.resize(grayim, (img_size[1], img_size[0]), interpolation=interp)\n",
    "    image = grayim.astype('float32')\n",
    "\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Necessary functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to generate predefined transformated images\n",
    "# input a list of images\n",
    "# output a list of transformed images and save them to the output directory\n",
    "def generate_affine_transformed_images(img_list, csv_file, img_count=None):\n",
    "\n",
    "    # Initialize the CSV file with a header\n",
    "    with open(csv_file, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Image\", \"Translate1\", \"Translate2\", \"Rotate\", \"Shear\", \"Scale\", \"SourceImage\"])\n",
    "\n",
    "    # Loop over the images, read the image, \n",
    "    # apply affine transformation and save it\n",
    "    for i, img_path in enumerate(img_list):\n",
    "        # Read the image as grayscale using cv2\n",
    "        image = load_image(img_path)\n",
    "\n",
    "        # Generate random affine transformations\n",
    "        translation = (\n",
    "            random.randint(-max_translation, max_translation),\n",
    "            random.randint(-max_translation, max_translation),\n",
    "        )\n",
    "        rotation = random.uniform(-max_rotation, max_rotation)\n",
    "        shear = random.uniform(-max_shear, max_shear)\n",
    "        scale = random.uniform(1.0, max_scale)\n",
    "\n",
    "        # Build the affine matrix using cv2\n",
    "        rows, cols = image.shape\n",
    "        M = cv2.getRotationMatrix2D((cols / 2, rows / 2), rotation, scale)\n",
    "        M[0, 1] = np.tan(np.radians(shear))\n",
    "        M[1, 0] = np.tan(np.radians(shear))\n",
    "        M[0, 2] = translation[0]\n",
    "        M[1, 2] = translation[1]\n",
    "\n",
    "        # Apply affine transformation using cv2\n",
    "        img_transformed = cv2.warpAffine(\n",
    "            image, M, (cols, rows), flags=cv2.INTER_LINEAR, borderMode=cv2.BORDER_CONSTANT, borderValue=0)\n",
    "        \n",
    "        # normalize image\n",
    "        image = image / 255.0\n",
    "        img_transformed = img_transformed / 255.0\n",
    "\n",
    "        # apply Superpoint to both images\n",
    "        sp = SuperPointFrontend('superpoint_v1.pth', nms_dist=4, conf_thresh=0.0155, nn_thresh=0.7, cuda=True)\n",
    "        pts1, desc1, heatmap1 = sp.run(image)\n",
    "        pts2, desc2, heatmap2 = sp.run(img_transformed)\n",
    "        print(f'image: {i}')\n",
    "        '''print(f'image: {np.max(image.flatten())}')\n",
    "        print(f'img_transformed: {np.max(img_transformed.flatten())}')\n",
    "        print(f'heatmap1: {heatmap1}')\n",
    "        print(f'heatmap2: {heatmap2}')'''\n",
    "\n",
    "        # plot all images as a grid\n",
    "        '''fig, ax = plt.subplots(2, 2, figsize=(10, 10))\n",
    "        ax = ax.flatten()\n",
    "        ax[0].imshow(image, cmap=\"gray\")\n",
    "        # ax[0].scatter(pts1[0, :], pts1[1, :], c=\"r\", s=1)\n",
    "        ax[0].set_title(\"Original\")\n",
    "        ax[1].imshow(img_transformed, cmap=\"gray\")\n",
    "        # ax[1].scatter(pts2[0, :], pts2[1, :], c=\"r\", s=1)\n",
    "        ax[1].set_title(\"Transformed\")\n",
    "        ax[2].imshow(heatmap1, cmap='hot', alpha=0.8)\n",
    "        ax[2].set_title(\"Original Heatmap\")\n",
    "        ax[3].imshow(heatmap2, cmap='hot', alpha=0.8)\n",
    "        ax[3].set_title(\"Transformed Heatmap\")\n",
    "        plt.show()'''\n",
    "\n",
    "        # Save original image\n",
    "        original_image_path = os.path.join(output_dir, f\"img_{i}.png\")\n",
    "        cv2.imwrite(original_image_path, image*255.0)\n",
    "        cv2.imwrite(os.path.join(output_dir, f\"img_{i}_heatmap.png\"), heatmap1*255.0)\n",
    "\n",
    "        # Save transformed image\n",
    "        transformed_image_path = os.path.join(output_dir, f\"img_{i}_transformed.png\")\n",
    "        cv2.imwrite(transformed_image_path, img_transformed*255.0)\n",
    "        cv2.imwrite(os.path.join(output_dir, f\"img_{i}_transformed_heatmap.png\"), heatmap2*255.0)\n",
    "\n",
    "        # Plot original and transformed image\n",
    "        '''plt.figure(figsize=(10, 5))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(image, cmap=\"gray\")\n",
    "        plt.title(f\"Original\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(img_transformed, cmap=\"gray\")\n",
    "        plt.title(\"Transformed\")\n",
    "        plt.savefig(os.path.join(plot_dir, f\"img_{i}_plot.png\"))\n",
    "        plt.close()'''\n",
    "\n",
    "        # Save image name and affine parameters to a CSV file\n",
    "        with open(csv_file, 'a', newline='') as csvfile:\n",
    "            writer = csv.writer(csvfile)\n",
    "            writer.writerow([f\"img_{i}.png\", translation[0], translation[1], rotation, shear, scale, img_path])\n",
    "\n",
    "        if img_count is not None and i >= img_count - 1:\n",
    "            break\n",
    "\n",
    "    print(f\"Generated {i + 1} images\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 0\n",
      "image: 1\n",
      "image: 2\n",
      "image: 3\n",
      "image: 4\n",
      "image: 5\n",
      "image: 6\n",
      "image: 7\n",
      "image: 8\n",
      "image: 9\n",
      "image: 10\n",
      "image: 11\n",
      "image: 12\n",
      "image: 13\n",
      "image: 14\n",
      "image: 15\n",
      "image: 16\n",
      "image: 17\n",
      "image: 18\n",
      "image: 19\n",
      "image: 20\n",
      "image: 21\n",
      "image: 22\n",
      "image: 23\n",
      "image: 24\n",
      "image: 25\n",
      "image: 26\n",
      "image: 27\n",
      "image: 28\n",
      "image: 29\n",
      "image: 30\n",
      "image: 31\n",
      "image: 32\n",
      "image: 33\n",
      "image: 34\n",
      "image: 35\n",
      "image: 36\n",
      "image: 37\n",
      "image: 38\n",
      "image: 39\n",
      "image: 40\n",
      "image: 41\n",
      "image: 42\n",
      "image: 43\n",
      "image: 44\n",
      "image: 45\n",
      "image: 46\n",
      "image: 47\n",
      "image: 48\n",
      "image: 49\n",
      "image: 50\n",
      "image: 51\n",
      "image: 52\n",
      "image: 53\n",
      "image: 54\n",
      "image: 55\n",
      "image: 56\n",
      "image: 57\n",
      "image: 58\n",
      "image: 59\n",
      "image: 60\n",
      "image: 61\n",
      "image: 62\n",
      "image: 63\n",
      "image: 64\n",
      "image: 65\n",
      "image: 66\n",
      "image: 67\n",
      "image: 68\n",
      "image: 69\n",
      "image: 70\n",
      "image: 71\n",
      "image: 72\n",
      "image: 73\n",
      "image: 74\n",
      "image: 75\n",
      "image: 76\n",
      "image: 77\n",
      "image: 78\n",
      "image: 79\n",
      "image: 80\n",
      "image: 81\n",
      "image: 82\n",
      "image: 83\n",
      "image: 84\n",
      "image: 85\n",
      "image: 86\n",
      "image: 87\n",
      "image: 88\n",
      "image: 89\n",
      "image: 90\n",
      "image: 91\n",
      "image: 92\n",
      "image: 93\n",
      "image: 94\n",
      "image: 95\n",
      "image: 96\n",
      "image: 97\n",
      "image: 98\n",
      "image: 99\n",
      "image: 100\n",
      "image: 101\n",
      "image: 102\n",
      "image: 103\n",
      "image: 104\n",
      "image: 105\n",
      "image: 106\n",
      "image: 107\n",
      "image: 108\n",
      "image: 109\n",
      "image: 110\n",
      "image: 111\n",
      "image: 112\n",
      "image: 113\n",
      "image: 114\n",
      "image: 115\n",
      "image: 116\n",
      "image: 117\n",
      "image: 118\n",
      "image: 119\n",
      "image: 120\n",
      "image: 121\n",
      "image: 122\n",
      "image: 123\n",
      "image: 124\n",
      "image: 125\n",
      "image: 126\n",
      "image: 127\n",
      "image: 128\n",
      "image: 129\n",
      "image: 130\n",
      "image: 131\n",
      "image: 132\n",
      "image: 133\n",
      "image: 134\n",
      "image: 135\n",
      "image: 136\n",
      "image: 137\n",
      "image: 138\n",
      "image: 139\n",
      "image: 140\n",
      "image: 141\n",
      "image: 142\n",
      "image: 143\n",
      "image: 144\n",
      "image: 145\n",
      "image: 146\n",
      "image: 147\n",
      "image: 148\n",
      "image: 149\n",
      "image: 150\n",
      "image: 151\n",
      "image: 152\n",
      "image: 153\n",
      "image: 154\n",
      "image: 155\n",
      "image: 156\n",
      "image: 157\n",
      "image: 158\n",
      "image: 159\n",
      "image: 160\n",
      "image: 161\n",
      "image: 162\n",
      "image: 163\n",
      "image: 164\n",
      "image: 165\n",
      "image: 166\n",
      "image: 167\n",
      "image: 168\n",
      "image: 169\n",
      "image: 170\n",
      "image: 171\n",
      "image: 172\n",
      "image: 173\n",
      "image: 174\n",
      "image: 175\n",
      "image: 176\n",
      "image: 177\n",
      "image: 178\n",
      "image: 179\n",
      "image: 180\n",
      "image: 181\n",
      "image: 182\n",
      "image: 183\n",
      "image: 184\n",
      "image: 185\n",
      "image: 186\n",
      "image: 187\n",
      "image: 188\n",
      "image: 189\n",
      "image: 190\n",
      "image: 191\n",
      "image: 192\n",
      "image: 193\n",
      "image: 194\n",
      "image: 195\n",
      "image: 196\n",
      "image: 197\n",
      "image: 198\n",
      "image: 199\n",
      "image: 200\n",
      "image: 201\n",
      "image: 202\n",
      "image: 203\n",
      "image: 204\n",
      "image: 205\n",
      "image: 206\n",
      "image: 207\n",
      "image: 208\n",
      "image: 209\n",
      "image: 210\n",
      "image: 211\n",
      "image: 212\n",
      "image: 213\n",
      "image: 214\n",
      "image: 215\n",
      "image: 216\n",
      "image: 217\n",
      "image: 218\n",
      "image: 219\n",
      "image: 220\n",
      "image: 221\n",
      "image: 222\n",
      "image: 223\n",
      "image: 224\n",
      "image: 225\n",
      "image: 226\n",
      "image: 227\n",
      "image: 228\n",
      "image: 229\n",
      "image: 230\n",
      "image: 231\n",
      "image: 232\n",
      "image: 233\n",
      "image: 234\n",
      "image: 235\n",
      "image: 236\n",
      "image: 237\n",
      "image: 238\n",
      "image: 239\n",
      "image: 240\n",
      "image: 241\n",
      "image: 242\n",
      "image: 243\n",
      "image: 244\n",
      "image: 245\n",
      "image: 246\n",
      "image: 247\n",
      "image: 248\n",
      "image: 249\n",
      "image: 250\n",
      "image: 251\n",
      "image: 252\n",
      "image: 253\n",
      "image: 254\n",
      "image: 255\n",
      "image: 256\n",
      "image: 257\n",
      "image: 258\n",
      "image: 259\n",
      "image: 260\n",
      "image: 261\n",
      "image: 262\n",
      "image: 263\n",
      "image: 264\n",
      "image: 265\n",
      "image: 266\n",
      "image: 267\n",
      "image: 268\n",
      "image: 269\n",
      "image: 270\n",
      "image: 271\n",
      "image: 272\n",
      "image: 273\n",
      "image: 274\n",
      "image: 275\n",
      "image: 276\n",
      "image: 277\n",
      "image: 278\n",
      "image: 279\n",
      "image: 280\n",
      "image: 281\n",
      "image: 282\n",
      "image: 283\n",
      "image: 284\n",
      "image: 285\n",
      "image: 286\n",
      "image: 287\n",
      "image: 288\n",
      "image: 289\n",
      "image: 290\n",
      "image: 291\n",
      "image: 292\n",
      "image: 293\n",
      "image: 294\n",
      "image: 295\n",
      "image: 296\n",
      "image: 297\n",
      "image: 298\n",
      "image: 299\n",
      "image: 300\n",
      "image: 301\n",
      "image: 302\n",
      "image: 303\n",
      "image: 304\n",
      "image: 305\n",
      "image: 306\n",
      "image: 307\n",
      "image: 308\n",
      "image: 309\n",
      "image: 310\n",
      "image: 311\n",
      "image: 312\n",
      "image: 313\n",
      "image: 314\n",
      "image: 315\n",
      "image: 316\n",
      "image: 317\n",
      "image: 318\n",
      "image: 319\n",
      "image: 320\n",
      "image: 321\n",
      "image: 322\n",
      "image: 323\n",
      "image: 324\n",
      "image: 325\n",
      "image: 326\n",
      "image: 327\n",
      "image: 328\n",
      "image: 329\n",
      "image: 330\n",
      "image: 331\n",
      "image: 332\n",
      "image: 333\n",
      "image: 334\n",
      "image: 335\n",
      "image: 336\n",
      "image: 337\n",
      "image: 338\n",
      "image: 339\n",
      "image: 340\n",
      "image: 341\n",
      "image: 342\n",
      "image: 343\n",
      "image: 344\n",
      "image: 345\n",
      "image: 346\n",
      "image: 347\n",
      "image: 348\n",
      "image: 349\n",
      "image: 350\n",
      "image: 351\n",
      "image: 352\n",
      "image: 353\n",
      "image: 354\n",
      "image: 355\n",
      "image: 356\n",
      "image: 357\n",
      "image: 358\n",
      "image: 359\n",
      "image: 360\n",
      "image: 361\n",
      "image: 362\n",
      "image: 363\n",
      "image: 364\n",
      "image: 365\n",
      "image: 366\n",
      "image: 367\n",
      "image: 368\n",
      "image: 369\n",
      "image: 370\n",
      "image: 371\n",
      "image: 372\n",
      "image: 373\n",
      "image: 374\n",
      "image: 375\n",
      "image: 376\n",
      "image: 377\n",
      "image: 378\n",
      "image: 379\n",
      "image: 380\n",
      "image: 381\n",
      "image: 382\n",
      "image: 383\n",
      "image: 384\n",
      "image: 385\n",
      "image: 386\n",
      "image: 387\n",
      "image: 388\n",
      "image: 389\n",
      "image: 390\n",
      "image: 391\n",
      "image: 392\n",
      "image: 393\n",
      "image: 394\n",
      "image: 395\n",
      "image: 396\n",
      "image: 397\n",
      "image: 398\n",
      "image: 399\n",
      "image: 400\n",
      "image: 401\n",
      "image: 402\n",
      "image: 403\n",
      "image: 404\n",
      "image: 405\n",
      "image: 406\n",
      "image: 407\n",
      "image: 408\n",
      "image: 409\n",
      "image: 410\n",
      "image: 411\n",
      "image: 412\n",
      "image: 413\n",
      "image: 414\n",
      "image: 415\n",
      "image: 416\n",
      "image: 417\n",
      "image: 418\n",
      "image: 419\n",
      "image: 420\n",
      "image: 421\n",
      "image: 422\n",
      "image: 423\n",
      "image: 424\n",
      "image: 425\n",
      "image: 426\n",
      "image: 427\n",
      "image: 428\n",
      "image: 429\n",
      "image: 430\n",
      "image: 431\n",
      "image: 432\n",
      "image: 433\n",
      "image: 434\n",
      "image: 435\n",
      "image: 436\n",
      "image: 437\n",
      "image: 438\n",
      "image: 439\n",
      "image: 440\n",
      "image: 441\n",
      "image: 442\n",
      "image: 443\n",
      "image: 444\n",
      "image: 445\n",
      "image: 446\n",
      "image: 447\n",
      "image: 448\n",
      "image: 449\n",
      "image: 450\n",
      "image: 451\n",
      "image: 452\n",
      "image: 453\n",
      "image: 454\n",
      "image: 455\n",
      "image: 456\n",
      "image: 457\n",
      "image: 458\n",
      "image: 459\n",
      "image: 460\n",
      "image: 461\n",
      "image: 462\n",
      "image: 463\n",
      "image: 464\n",
      "image: 465\n",
      "image: 466\n",
      "image: 467\n",
      "image: 468\n",
      "image: 469\n",
      "image: 470\n",
      "image: 471\n",
      "image: 472\n",
      "image: 473\n",
      "image: 474\n",
      "image: 475\n",
      "image: 476\n",
      "image: 477\n",
      "image: 478\n",
      "image: 479\n",
      "image: 480\n",
      "image: 481\n",
      "image: 482\n",
      "image: 483\n",
      "image: 484\n",
      "image: 485\n",
      "image: 486\n",
      "image: 487\n",
      "image: 488\n",
      "image: 489\n",
      "image: 490\n",
      "image: 491\n",
      "image: 492\n",
      "image: 493\n",
      "image: 494\n",
      "image: 495\n",
      "image: 496\n",
      "image: 497\n",
      "image: 498\n",
      "image: 499\n",
      "Generated 500 images\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# generate synthetic images for each source training image\n",
    "generate_affine_transformed_images(image_list,'synthetic_dataset_eye_train.csv', img_count=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_47849/3867127529.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_test['image_path'] = df_test['Directory'] + '/' + df_test['Source image']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image: 1\n",
      "image: 2\n",
      "image: 3\n",
      "image: 4\n",
      "image: 5\n",
      "image: 6\n",
      "image: 7\n",
      "image: 8\n",
      "image: 9\n",
      "image: 10\n",
      "image: 11\n",
      "image: 12\n",
      "image: 13\n",
      "image: 14\n",
      "image: 15\n",
      "image: 16\n",
      "image: 17\n",
      "image: 18\n",
      "image: 19\n",
      "image: 20\n",
      "image: 21\n",
      "image: 22\n",
      "image: 23\n",
      "image: 24\n",
      "image: 25\n",
      "image: 26\n",
      "image: 27\n",
      "image: 28\n",
      "image: 29\n",
      "image: 30\n",
      "image: 31\n",
      "image: 32\n",
      "image: 33\n",
      "image: 34\n",
      "image: 35\n",
      "image: 36\n",
      "image: 37\n",
      "image: 38\n",
      "image: 39\n",
      "image: 40\n",
      "image: 41\n",
      "image: 42\n",
      "image: 43\n",
      "image: 44\n",
      "image: 45\n",
      "image: 46\n",
      "image: 47\n",
      "image: 48\n",
      "image: 49\n",
      "image: 50\n",
      "image: 51\n",
      "image: 52\n",
      "image: 53\n",
      "image: 54\n",
      "image: 55\n",
      "image: 56\n",
      "image: 57\n",
      "image: 58\n",
      "image: 59\n",
      "image: 60\n",
      "image: 61\n",
      "image: 62\n",
      "image: 63\n",
      "image: 64\n",
      "image: 65\n",
      "image: 66\n",
      "image: 67\n",
      "image: 68\n",
      "image: 69\n",
      "image: 70\n",
      "image: 71\n",
      "image: 72\n",
      "image: 73\n",
      "image: 74\n",
      "image: 75\n",
      "image: 76\n",
      "image: 77\n",
      "image: 78\n",
      "image: 79\n",
      "image: 80\n",
      "image: 81\n",
      "image: 82\n",
      "image: 83\n",
      "image: 84\n",
      "image: 85\n",
      "image: 86\n",
      "image: 87\n",
      "image: 88\n",
      "image: 89\n",
      "image: 90\n",
      "image: 91\n",
      "image: 92\n",
      "image: 93\n",
      "image: 94\n",
      "image: 95\n",
      "image: 96\n",
      "image: 97\n",
      "image: 98\n",
      "image: 99\n",
      "image: 100\n",
      "image: 101\n",
      "image: 102\n",
      "image: 103\n",
      "image: 104\n",
      "image: 105\n",
      "image: 106\n",
      "image: 107\n",
      "image: 108\n",
      "image: 109\n",
      "image: 110\n",
      "image: 111\n",
      "image: 112\n",
      "image: 113\n",
      "image: 114\n",
      "image: 115\n",
      "image: 116\n",
      "image: 117\n",
      "image: 118\n",
      "image: 119\n",
      "image: 120\n",
      "image: 121\n",
      "image: 122\n",
      "image: 123\n",
      "image: 124\n",
      "image: 125\n",
      "image: 126\n",
      "image: 127\n",
      "image: 128\n",
      "image: 129\n",
      "image: 130\n",
      "image: 131\n",
      "image: 132\n",
      "image: 133\n",
      "image: 134\n",
      "image: 135\n",
      "image: 136\n",
      "image: 137\n",
      "image: 138\n",
      "image: 139\n",
      "image: 140\n",
      "image: 141\n",
      "image: 142\n",
      "image: 143\n",
      "image: 144\n",
      "image: 145\n",
      "image: 146\n",
      "image: 147\n",
      "image: 148\n",
      "image: 149\n",
      "image: 150\n",
      "image: 151\n",
      "image: 152\n",
      "image: 153\n",
      "image: 154\n",
      "image: 155\n",
      "image: 156\n",
      "image: 157\n",
      "image: 158\n",
      "image: 159\n",
      "image: 160\n",
      "image: 161\n",
      "image: 162\n",
      "image: 163\n",
      "image: 164\n",
      "image: 165\n",
      "image: 166\n",
      "image: 167\n",
      "image: 168\n",
      "image: 169\n",
      "image: 170\n",
      "image: 171\n",
      "image: 172\n",
      "image: 173\n",
      "image: 174\n",
      "image: 175\n",
      "image: 176\n",
      "image: 177\n",
      "image: 178\n",
      "image: 179\n",
      "image: 180\n",
      "image: 181\n",
      "image: 182\n",
      "image: 183\n",
      "image: 184\n",
      "image: 185\n",
      "image: 186\n",
      "image: 187\n",
      "image: 188\n",
      "image: 189\n",
      "image: 190\n",
      "image: 191\n",
      "image: 192\n",
      "image: 193\n",
      "image: 194\n",
      "image: 195\n",
      "image: 196\n",
      "image: 197\n",
      "image: 198\n",
      "image: 199\n",
      "Generated 200 images\n"
     ]
    }
   ],
   "source": [
    "# do the same for the test images\n",
    "df_test = df[df['training'] == 1]\n",
    "df_test['image_path'] = df_test['Directory'] + '/' + df_test['Source image']\n",
    "image_list_test = df_test['image_path'].unique()\n",
    "\n",
    "# Define parameters\n",
    "image_size = (512, 512)  # Size of the images\n",
    "output_dir = \"Dataset/synthetic_eye_dataset_test\"  # Output directory\n",
    "plot_dir = \"Dataset/synthetic_eye_dataset_test/plot\"\n",
    "max_translation = 20  # Maximum translation in pixels\n",
    "max_rotation = 10  # Maximum rotation in degrees\n",
    "max_shear = 5  # Maximum shear in degrees\n",
    "max_scale = 1.1  # Maximum scale factor\n",
    "\n",
    "# Create output directory if it doesn't exist\n",
    "os.makedirs(output_dir, exist_ok=True)\n",
    "os.makedirs(plot_dir, exist_ok=True)\n",
    "\n",
    "# generate synthetic images for each source test image\n",
    "generate_affine_transformed_images(image_list_test, 'synthetic_dataset_eye_test.csv', img_count=200)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spppt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
