{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import cv2\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "from skimage.measure import ransac\n",
    "from skimage.transform import FundamentalMatrixTransform, AffineTransform\n",
    "\n",
    "# Suppress the specific warning\n",
    "import csv\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from torch import nn, optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils import data\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "from utils.utils0 import *\n",
    "from utils.utils1 import *\n",
    "from utils.utils1 import ModelParams, DL_affine_plot, loss_extra\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f'Device: {device}')\n",
    "\n",
    "# Stub to warn about opencv version.\n",
    "if int(cv2.__version__[0]) < 3: # pragma: no cover\n",
    "  print('Warning: OpenCV 3 is not installed')\n",
    "\n",
    "image_size = 256\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cases, model parameters\n",
    "- Supervised DL w/ groundtruth affine transformation parameters (MSE params, MSE, NCC images)\n",
    "    - Synthetic eye\n",
    "    - Synthetic shape\n",
    "- Unsupervised DL (MSE, NCC images)\n",
    "    - Actual eye data\n",
    "    - Synthetic eye\n",
    "    - Synthetic shape\n",
    "- Data\n",
    "    - only images\n",
    "    - only heatmaps\n",
    "    - images & heatmaps\n",
    "- Loss function\n",
    "    - MSE affine parameters\n",
    "    - MSE, NCC images\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model name:  dataset1_sup1_image1_heatmaps0_loss_image2\n",
      "Model code:  11102_0.001_0_2_1\n",
      "Model params:  {'dataset': 1, 'sup': 1, 'image': 1, 'heatmaps': 0, 'loss_image_case': 2, 'loss_image': <utils.utils1.MSE_SSIM object at 0x7fc38839d430>, 'loss_affine': <utils.utils1.loss_affine object at 0x7fc38839d160>, 'learning_rate': 0.001, 'decay_rate': 0.96, 'start_epoch': 0, 'num_epochs': 2, 'batch_size': 1, 'model_name': 'dataset1_sup1_image1_heatmaps0_loss_image2'}\n",
      "\n",
      "Model name:  dataset1_sup1_image1_heatmaps0_loss_image2\n",
      "Model code:  11102_0.001_0_2_1\n",
      "Dataset used:  Synthetic eye\n",
      "Supervised or unsupervised model:  Supervised\n",
      "Image type:  Image used\n",
      "Heatmaps used:  Heatmaps not used\n",
      "Loss function case:  2\n",
      "Loss function for image:  <utils.utils1.MSE_SSIM object at 0x7fc38839d430>\n",
      "Loss function for affine:  <utils.utils1.loss_affine object at 0x7fc38839d160>\n",
      "Learning rate:  0.001\n",
      "Decay rate:  0.96\n",
      "Start epoch:  0\n",
      "Number of epochs:  2\n",
      "Batch size:  1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model_params = ModelParams(sup=1, dataset=1, image=1, heatmaps=0, \n",
    "                           loss_image=2, num_epochs=2)\n",
    "model_params.print_explanation()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "## SuperPoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SuperPoint import SuperPointFrontend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ImgReg Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.SPaffineNet import SP_AffineNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SP ImgReg model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dx = 2.0\n",
    "# dy = 3.0\n",
    "# translation_matrix = torch.tensor([[1.0, 0.0, dx],\n",
    "#                                   [0.0, 1.0, dy]])\n",
    "# print(translation_matrix.shape)\n",
    "\n",
    "# x = torch.tensor([1.0, 2.0, 3.0])\n",
    "# y = torch.tensor([4.0, 5.0, 6.0])\n",
    "\n",
    "# # Combine x and y into a (2, N) tensor\n",
    "# points = torch.stack((x, y), dim=0)\n",
    "\n",
    "# ones = torch.ones(points.shape[1]).unsqueeze(0)\n",
    "# print(ones.shape)\n",
    "\n",
    "# points = torch.cat((points, ones), dim=0)\n",
    "# print(points.shape)\n",
    "\n",
    "# # Apply the transformation\n",
    "# transformed_points = torch.mm(translation_matrix, points)\n",
    "# transformed_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def transform_points(points, affine_params):\n",
    "#     affine_params = affine_params.double()\n",
    "#     # Convert points to tensor\n",
    "#     points = torch.tensor(points).double().to(affine_params.device)\n",
    "#     # reshape points tensor to (2, N) shape\n",
    "#     points = points.reshape(2, -1)\n",
    "\n",
    "\n",
    "#     # Add row of ones to points tensor\n",
    "#     ones = torch.ones(points.shape[1], device=points.device).unsqueeze(0)\n",
    "#     points = torch.cat((points, ones), dim=0)\n",
    "\n",
    "#     # Apply affine transformation\n",
    "#     transformed_points = torch.mm(affine_params.squeeze(0), points)\n",
    "\n",
    "#     # Remove last row of ones\n",
    "#     # transformed_points = transformed_points[:2, :]\n",
    "#     # print('transformed_points: ', transformed_points.shape)\n",
    "\n",
    "#     return transformed_points\n",
    "\n",
    "# # define model\n",
    "# class SP_AffineNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(SP_AffineNet, self).__init__()\n",
    "#         self.superpoint = SuperPointFrontend('utils/superpoint_v1.pth', nms_dist=4,\n",
    "#                           conf_thresh=0.015, nn_thresh=0.7, cuda=True)\n",
    "#         self.affineNet = AffineNet()\n",
    "#         self.nn_thresh = 0.7\n",
    "\n",
    "#     def forward(self, source_image, target_image):\n",
    "#         # source_image = source_image.to(device)\n",
    "#         # target_image = target_image.to(device)\n",
    "\n",
    "#         # print('source_image: ', source_image.shape)\n",
    "#         # print('target_image: ', target_image.shape)\n",
    "#         points1, desc1, heatmap1 = self.superpoint(source_image[0, 0, :, :].cpu().numpy())\n",
    "#         points2, desc2, heatmap2 = self.superpoint(target_image[0, 0, :, :].cpu().numpy())\n",
    "\n",
    "#         if model_params.heatmaps == 0:\n",
    "#             affine_params = self.affineNet(source_image, target_image)\n",
    "#         elif model_params.heatmaps == 1:\n",
    "#             affine_params = self.affineNet(source_image, target_image, heatmap1, heatmap2)\n",
    "\n",
    "#         # transform the source image using the affine parameters\n",
    "#         # using F.affine_grid and F.grid_sample\n",
    "#         transformed_source_affine = tensor_affine_transform(source_image, affine_params)\n",
    "\n",
    "#         # match the points between the two images\n",
    "#         tracker = PointTracker(5, nn_thresh=0.7)\n",
    "#         try:\n",
    "#             matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=self.nn_thresh)\n",
    "#         except:\n",
    "#             print('No matches found')\n",
    "#             # TODO: find a better way to do this\n",
    "#             try:\n",
    "#                 while matches.shape[1] < 3 and self.nn_thresh > 0.1:\n",
    "#                     self.nn_thresh = self.nn_thresh - 0.1\n",
    "#                     matches = tracker.nn_match_two_way(desc1, desc2, nn_thresh=self.nn_thresh)\n",
    "#             except:\n",
    "#                 return transformed_source_affine, affine_params, [], [], [], [], [], [], []\n",
    "\n",
    "#         # take the elements from points1 and points2 using the matches as indices\n",
    "#         matches1 = points1[:2, matches[0, :].astype(int)]\n",
    "#         matches2 = points2[:2, matches[1, :].astype(int)]\n",
    "\n",
    "#         # transform the points using the affine parameters\n",
    "#         matches1_transformed = transform_points(matches1.T[None, :, :], affine_params.cpu().detach())\n",
    "#         return transformed_source_affine, affine_params, matches1, matches2, matches1_transformed, desc1, desc2, heatmap1, heatmap2\n",
    "\n",
    "#         # return transformed_source_affine, affine_params\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.datagen import datagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset: 0, is_train: True, sup: False\n",
      "Training eye dataset\n",
      "Number of training data:  500\n",
      "index, source_img.shape,       target_img.shape\n",
      "0 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "1 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "2 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "\n",
      "\n",
      "dataset: 0, is_train: True, sup: True\n",
      "Training eye dataset\n",
      "Number of training data:  500\n",
      "skipping\n",
      "\n",
      "\n",
      "dataset: 0, is_train: False, sup: False\n",
      "Test eye dataset\n",
      "Number of testing data:  100\n",
      "index, source_img.shape,       target_img.shape\n",
      "0 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "1 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "2 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "\n",
      "\n",
      "dataset: 0, is_train: False, sup: True\n",
      "Test eye dataset\n",
      "Number of testing data:  100\n",
      "skipping\n",
      "\n",
      "\n",
      "dataset: 1, is_train: True, sup: False\n",
      "index, source_img.shape,       target_img.shape\n",
      "0 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "1 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "2 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "\n",
      "\n",
      "dataset: 1, is_train: True, sup: True\n",
      "index, source_img.shape,       target_img.shape\n",
      "index, source_img.shape,       target_img.shape,            affine_params.shape\n",
      "0 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "1 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "2 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "3 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "4 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "5 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "\n",
      "\n",
      "dataset: 1, is_train: False, sup: False\n",
      "index, source_img.shape,       target_img.shape\n",
      "0 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "1 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "2 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256])\n",
      "\n",
      "\n",
      "dataset: 1, is_train: False, sup: True\n",
      "index, source_img.shape,       target_img.shape\n",
      "index, source_img.shape,       target_img.shape,            affine_params.shape\n",
      "0 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "1 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "2 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "3 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "4 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "5 torch.Size([1, 1, 256, 256]) torch.Size([1, 1, 256, 256]) torch.Size([1, 6])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# test datagen for all datasets and training and testing\n",
    "for dataset in range(2): # don't forget to change this back to 2\n",
    "    for is_train in [True, False]:\n",
    "        for sup in [False, True]:\n",
    "            print(f'dataset: {dataset}, is_train: {is_train}, sup: {sup}')\n",
    "            dataloader = datagen(dataset, is_train, sup)\n",
    "            \n",
    "            if sup==1 and dataset==0:\n",
    "                print('skipping')\n",
    "                pass\n",
    "            else:\n",
    "                try:\n",
    "                    print('index, source_img.shape,       target_img.shape')\n",
    "                    for i, (source_img, target_img) in enumerate(dataloader):\n",
    "                        print(i, source_img.shape, target_img.shape)\n",
    "                        if i == 2:\n",
    "                            break\n",
    "                except ValueError:\n",
    "                    print('index, source_img.shape,       target_img.shape,            affine_params.shape')\n",
    "                    for i, batch in enumerate(dataloader):\n",
    "                        print(i, batch[0].shape, batch[1].shape, batch[2].shape)\n",
    "                        if i == 5:\n",
    "                            break\n",
    "            print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training\n",
    "## Dataset initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  [torch.Size([1, 1, 256, 256]), torch.Size([1, 1, 256, 256]), torch.Size([1, 6])]\n",
      "Test set:  [torch.Size([1, 1, 256, 256]), torch.Size([1, 1, 256, 256]), torch.Size([1, 6])]\n"
     ]
    }
   ],
   "source": [
    "train_dataset = datagen(model_params.dataset, True, model_params.sup)\n",
    "test_dataset = datagen(model_params.dataset, False, model_params.sup)\n",
    "\n",
    "# Get sample batch\n",
    "print('Train set: ', [x.shape for x in next(iter(train_dataset))])\n",
    "print('Test set: ', [x.shape for x in next(iter(test_dataset))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model initialize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dataset1_sup1_image1_heatmaps0_loss_image2\n",
      "\n",
      "Model name:  dataset1_sup1_image1_heatmaps0_loss_image2\n",
      "Model code:  11102_0.001_0_2_1\n",
      "Dataset used:  Synthetic eye\n",
      "Supervised or unsupervised model:  Supervised\n",
      "Image type:  Image used\n",
      "Heatmaps used:  Heatmaps not used\n",
      "Loss function case:  2\n",
      "Loss function for image:  <utils.utils1.MSE_SSIM object at 0x7fc38839d430>\n",
      "Loss function for affine:  <utils.utils1.loss_affine object at 0x7fc38839d160>\n",
      "Learning rate:  0.001\n",
      "Decay rate:  0.96\n",
      "Start epoch:  0\n",
      "Number of epochs:  2\n",
      "Batch size:  1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print case\n",
    "print(model_params)\n",
    "model_params.print_explanation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running new version (not run SP on source image)\n",
      "SP_AffineNet(\n",
      "  (affineNet): AffineNet(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv1s): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv2s): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv3s): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv4s): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc4): Linear(in_features=32, out_features=6, bias=True)\n",
      "    (aPooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (ReLU): LeakyReLU(negative_slope=0.01)\n",
      "    (Act1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (Act2): GroupNorm(64, 128, eps=1e-05, affine=True)\n",
      "    (Act3): GroupNorm(128, 256, eps=1e-05, affine=True)\n",
      "    (Act4): GroupNorm(256, 512, eps=1e-05, affine=True)\n",
      "    (Act5): GroupNorm(256, 512, eps=1e-05, affine=True)\n",
      "  )\n",
      ")\n",
      "Loaded model from trained_models/10102_0.001_0_20_1_20230930-091532.pth\n",
      "starting at epoch 20\n"
     ]
    }
   ],
   "source": [
    "model = SP_AffineNet(model_params).to(device)\n",
    "print(model)\n",
    "\n",
    "parameters = model.parameters()\n",
    "optimizer = optim.Adam(parameters, model_params.learning_rate)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: model_params.decay_rate ** epoch)\n",
    "model_path = 'trained_models/10102_0.001_0_20_1_20230930-091532.pth'\n",
    "\n",
    "# if a model is loaded, the training will continue from the epoch it was saved at\n",
    "try:\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model_params.start_epoch = int(model_path.split('/')[-1].split('_')[3])\n",
    "    print(f'Loaded model from {model_path}\\nstarting at epoch {model_params.start_epoch}')\n",
    "except:\n",
    "    model_params.start_epoch = 0\n",
    "    print('No model loaded, starting from scratch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define training function\n",
    "def train(model, model_params, timestamp):\n",
    "    # Define loss function based on supervised or unsupervised learning\n",
    "    criterion = model_params.loss_image\n",
    "    # extra = loss_extra()\n",
    "\n",
    "    if model_params.sup:\n",
    "        criterion_affine = nn.MSELoss()\n",
    "        # TODO: add loss for points1_affine and points2, Euclidean distance\n",
    "\n",
    "    # Define optimizer\n",
    "    optimizer = optim.Adam(model.parameters(), lr=model_params.learning_rate)\n",
    "\n",
    "    # Create empty list to store epoch number, train loss and validation loss\n",
    "    epoch_loss_list = []\n",
    "    \n",
    "    # Create output directory\n",
    "    output_dir = f\"output/{model_params.get_model_code()}_{timestamp}\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Train model\n",
    "    for epoch in range(model_params.start_epoch, model_params.num_epochs):\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        running_loss = 0.0\n",
    "        train_bar = tqdm(train_dataset, desc=f'Training Epoch {epoch+1}/{model_params.num_epochs}')\n",
    "        for i, data in enumerate(train_bar):\n",
    "            # Get images and affine parameters\n",
    "            if model_params.sup:\n",
    "                source_image, target_image, affine_params_true = data\n",
    "            else:\n",
    "                source_image, target_image = data\n",
    "            source_image = source_image.to(device)\n",
    "            target_image = target_image.to(device)\n",
    "\n",
    "            # Forward + backward + optimize\n",
    "            outputs = model(source_image, target_image)\n",
    "            # for i in range(len(outputs)):\n",
    "            #         print(i, outputs[i].shape)\n",
    "            # 0 torch.Size([1, 1, 256, 256])\n",
    "            # 1 torch.Size([1, 2, 3])\n",
    "            # 2 (2, 4)\n",
    "            # 3 (2, 4)\n",
    "            # 4 (1, 4, 2)\n",
    "            # 5 (256, 9)\n",
    "            # 6 (256, 16)\n",
    "            # 7 (256, 256)\n",
    "            # 8 (256, 256)\n",
    "            transformed_source_affine = outputs[0] # image\n",
    "            affine_params_predicted = outputs[1] # affine parameters\n",
    "            points1 = outputs[2]\n",
    "            points2 = outputs[3]\n",
    "            points1_affine = np.array(outputs[4])\n",
    "\n",
    "            # print(f\"affine_params_true: {affine_params_true}\")\n",
    "            # print(f\"affine_params_predicted: {affine_params_predicted}\\n\")\n",
    "\n",
    "            try:\n",
    "                points1_affine = points1_affine.reshape(points1_affine.shape[2], points1_affine.shape[1])\n",
    "            except:\n",
    "                pass\n",
    "            desc1 = outputs[5]\n",
    "            desc2 = outputs[6]\n",
    "            heatmap1 = outputs[7]\n",
    "            heatmap2 = outputs[8]\n",
    "\n",
    "            loss = criterion(transformed_source_affine, target_image)\n",
    "            # loss += extra(affine_params_predicted)\n",
    "            if model_params.sup:\n",
    "                loss_affine = criterion_affine(affine_params_true.view(1, 2, 3), affine_params_predicted.cpu())\n",
    "                # TODO: add loss for points1_affine and points2, Euclidean distance\n",
    "                # loss_points = criterion_points(points1_affine, points2)\n",
    "\n",
    "                loss += loss_affine\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Plot images if i < 5\n",
    "            if i < 5:\n",
    "                DL_affine_plot(f\"epoch{epoch+1}_train\", output_dir,\n",
    "                    f\"{i}\", \"_\", source_image[0, 0, :, :].detach().cpu().numpy(), \n",
    "                    target_image[0, 0, :, :].detach().cpu().numpy(), \n",
    "                    transformed_source_affine[0, 0, :, :].detach().cpu().numpy(),\n",
    "                    points1, points2, points1_affine, desc1, desc2, \n",
    "                    affine_params=affine_params_predicted, heatmap1=heatmap1, heatmap2=heatmap2, plot=True)\n",
    "\n",
    "            # Print statistics\n",
    "            running_loss += loss.item()\n",
    "            train_bar.set_postfix({'loss': running_loss / (i+1)})\n",
    "        print(f'Training Epoch {epoch+1}/{model_params.num_epochs} loss: {running_loss / len(train_dataset)}')\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        # Validate model\n",
    "        validation_loss = 0.0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            for i, data in enumerate(test_dataset, 0):\n",
    "                # Get images and affine parameters\n",
    "                if model_params.sup:\n",
    "                    source_image, target_image, affine_params_true = data\n",
    "                else:\n",
    "                    source_image, target_image = data\n",
    "                source_image = source_image.to(device)\n",
    "                target_image = target_image.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(source_image, target_image)\n",
    "                # for i in range(len(outputs)):\n",
    "                #     print(i, outputs[i].shape)\n",
    "                transformed_source_affine = outputs[0]\n",
    "                affine_params_predicted = outputs[1]\n",
    "                points1 = outputs[2]\n",
    "                points2 = outputs[3]\n",
    "                points1_affine = np.array(outputs[4])\n",
    "                try:\n",
    "                    points1_affine = points1_affine.reshape(points1_affine.shape[2], points1_affine.shape[1])\n",
    "                except:\n",
    "                    pass\n",
    "                desc1 = outputs[5]\n",
    "                desc2 = outputs[6]\n",
    "                heatmap1 = outputs[7]\n",
    "                heatmap2 = outputs[8]\n",
    "\n",
    "                loss = criterion(transformed_source_affine, target_image)\n",
    "                # loss += extra(affine_params_predicted)\n",
    "                if model_params.sup:\n",
    "                    loss_affine = criterion_affine(affine_params_true.view(1, 2, 3), affine_params_predicted.cpu())\n",
    "                    # TODO: add loss for points1_affine and points2, Euclidean distance\n",
    "                    # loss_points = criterion_points(points1_affine, points2)\n",
    "                    loss += loss_affine\n",
    "\n",
    "                # Add to validation loss\n",
    "                validation_loss += loss.item()\n",
    "\n",
    "                # Plot images if i < 5\n",
    "                if i < 5:\n",
    "                    DL_affine_plot(f\"epoch{epoch+1}_valid\", output_dir,\n",
    "                        f\"{i}\", \"_\", source_image[0, 0, :, :].cpu().numpy(), target_image[0, 0, :, :].cpu().numpy(), \\\n",
    "                        transformed_source_affine[0, 0, :, :].cpu().numpy(),\n",
    "                        points1, points2, points1_affine, desc1, desc2, \\\n",
    "                        affine_params=affine_params_predicted, heatmap1=heatmap1, heatmap2=heatmap2, plot=True)\n",
    "\n",
    "        # Print validation statistics\n",
    "        validation_loss /= len(test_dataset)\n",
    "        print(f'Validation Epoch {epoch+1}/{model_params.num_epochs} loss: {validation_loss}')\n",
    "\n",
    "        # Append epoch number, train loss and validation loss to epoch_loss_list\n",
    "        epoch_loss_list.append([epoch+1, running_loss / len(train_dataset), validation_loss])\n",
    "\n",
    "    print('Finished Training')\n",
    "\n",
    "    # delete all txt files in output_dir\n",
    "    for file in os.listdir(output_dir):\n",
    "        if file.endswith(\".txt\"):\n",
    "            os.remove(os.path.join(output_dir, file))\n",
    "\n",
    "    # Extract epoch number, train loss and validation loss from epoch_loss_list\n",
    "    epoch = [x[0] for x in epoch_loss_list]\n",
    "    train_loss = [x[1] for x in epoch_loss_list]\n",
    "    val_loss = [x[2] for x in epoch_loss_list]\n",
    "\n",
    "    save_plot_name = f\"{output_dir}/loss_{model_params.get_model_code()}_epoch{model_params.num_epochs}_{timestamp}.png\"\n",
    "\n",
    "    # Plot train loss and validation loss against epoch number\n",
    "    plt.plot(epoch, train_loss, label='Train Loss')\n",
    "    plt.plot(epoch, val_loss, label='Validation Loss')\n",
    "    plt.title('Train and Validation Loss')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plt.savefig(save_plot_name)\n",
    "    # plt.show()\n",
    "\n",
    "    # Return epoch_loss_list\n",
    "    return epoch_loss_list\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## working code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2: 100%|██████████| 920/920 [02:45<00:00,  5.56it/s, loss=1.11e+7]\n",
      "/home/pkhamchuai/miniconda3/envs/spppt/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:139: UserWarning: Detected call of `lr_scheduler.step()` before `optimizer.step()`. In PyTorch 1.1.0 and later, you should call them in the opposite order: `optimizer.step()` before `lr_scheduler.step()`.  Failure to do this will result in PyTorch skipping the first value of the learning rate schedule. See more details at https://pytorch.org/docs/stable/optim.html#how-to-adjust-learning-rate\n",
      "  warnings.warn(\"Detected call of `lr_scheduler.step()` before `optimizer.step()`. \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 1/2 loss: 11135864.591112332\n",
      "Validation Epoch 1/2 loss: 16743949.926267281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2: 100%|██████████| 920/920 [02:34<00:00,  5.97it/s, loss=9.37e+7]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Epoch 2/2 loss: 93668476.02814199\n",
      "Validation Epoch 2/2 loss: 224074614.41474655\n",
      "Finished Training\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "loss_list = train(model, model_params, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training output:\n",
      "[1, 11135864.591112332, 16743949.926267281]\n",
      "[2, 93668476.02814199, 224074614.41474655]\n"
     ]
    }
   ],
   "source": [
    "print(\"Training output:\")\n",
    "for i in range(len(loss_list)):\n",
    "    print(loss_list[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_models/11102_0.001_0_2_1_20231009-150043.pth\n"
     ]
    }
   ],
   "source": [
    "model_save_path = \"trained_models/\"\n",
    "model_name_to_save = model_save_path + f\"{model_params.get_model_code()}_{timestamp}.pth\"\n",
    "print(model_name_to_save)\n",
    "torch.save(model.state_dict(), model_name_to_save)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model (loading and inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save results and export metrics to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SP_AffineNet(\n",
      "  (affineNet): AffineNet(\n",
      "    (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv2): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv3): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv4): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv5): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (conv1s): Conv2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv2s): Conv2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv3s): Conv2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (conv4s): Conv2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "    (fc1): Linear(in_features=1024, out_features=128, bias=True)\n",
      "    (fc2): Linear(in_features=128, out_features=64, bias=True)\n",
      "    (fc3): Linear(in_features=64, out_features=32, bias=True)\n",
      "    (fc4): Linear(in_features=32, out_features=6, bias=True)\n",
      "    (aPooling): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (ReLU): LeakyReLU(negative_slope=0.01)\n",
      "    (Act1): GroupNorm(32, 64, eps=1e-05, affine=True)\n",
      "    (Act2): GroupNorm(64, 128, eps=1e-05, affine=True)\n",
      "    (Act3): GroupNorm(128, 256, eps=1e-05, affine=True)\n",
      "    (Act4): GroupNorm(256, 512, eps=1e-05, affine=True)\n",
      "    (Act5): GroupNorm(256, 512, eps=1e-05, affine=True)\n",
      "  )\n",
      ")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 632,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SPmodel = SP_AffineNet().to(device)\n",
    "print(model)\n",
    "\n",
    "parameters = model.parameters()\n",
    "optimizer = optim.Adam(parameters, model_params.learning_rate)\n",
    "scheduler = optim.lr_scheduler.LambdaLR(optimizer, lambda epoch: model_params.decay_rate ** epoch)\n",
    "\n",
    "model.load_state_dict(torch.load(model_name_to_save))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Testing:: 100%|██████████| 217/217 [01:49<00:00,  1.98it/s]\n"
     ]
    }
   ],
   "source": [
    "def test(model, model_params, timestamp):\n",
    "    # Set model to training mode\n",
    "    model.eval()\n",
    "\n",
    "    # Create output directory\n",
    "    output_dir = f\"output/{model_params.get_model_code()}_{timestamp}_test\"\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Validate model\n",
    "    # validation_loss = 0.0\n",
    "\n",
    "    # create a csv file to store the metrics\n",
    "    csv_file = f\"{output_dir}/metrics.csv\"\n",
    "    with open(csv_file, 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        # matches1_transformed.shape[-1], mse_before, mse12, tre_before, tre12, \\\n",
    "        # mse12_image, ssim12_image, \n",
    "        writer.writerow([\"index\", \"mse_before\", \"mse12\", \"tre_before\", \"tre12\", \"mse12_image_before\", \"mse12_image\", \"ssim12_image_before\", \"ssim12_image\"])\n",
    "\n",
    "    with torch.no_grad():\n",
    "        testbar = tqdm(test_dataset, desc=f'Testing:')\n",
    "        for i, data in enumerate(testbar, 0):\n",
    "            # Get images and affine parameters\n",
    "            if model_params.sup:\n",
    "                source_image, target_image, affine_params_true = data\n",
    "            else:\n",
    "                source_image, target_image = data\n",
    "            source_image = source_image.to(device)\n",
    "            target_image = target_image.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(source_image, target_image)\n",
    "            # for i in range(len(outputs)):\n",
    "            #     print(i, outputs[i].shape)\n",
    "            transformed_source_affine = outputs[0]\n",
    "            affine_params_predicted = outputs[1]\n",
    "            points1 = outputs[2]\n",
    "            points2 = outputs[3]\n",
    "            points1_affine = np.array(outputs[4])\n",
    "            try:\n",
    "                points1_affine = points1_affine.reshape(points1_affine.shape[2], points1_affine.shape[1])\n",
    "            except:\n",
    "                pass\n",
    "            desc1 = outputs[5]\n",
    "            desc2 = outputs[6]\n",
    "            heatmap1 = outputs[7]\n",
    "            heatmap2 = outputs[8]\n",
    "\n",
    "            if i < 50:\n",
    "                plot_ = True\n",
    "            else:\n",
    "                plot_ = False\n",
    "\n",
    "            results = DL_affine_plot(f\"{i+1}\", output_dir,\n",
    "                f\"{i}\", \"_\", source_image[0, 0, :, :].cpu().numpy(), target_image[0, 0, :, :].cpu().numpy(), \\\n",
    "                transformed_source_affine[0, 0, :, :].cpu().numpy(), \\\n",
    "                points1, points2, points1_affine, desc1, desc2, \\\n",
    "                    affine_params=affine_params_predicted, heatmap1=heatmap1, heatmap2=heatmap2, plot=plot_)\n",
    "\n",
    "            # calculate metrics\n",
    "            # matches1_transformed = results[0]\n",
    "            mse_before = results[1]\n",
    "            mse12 = results[2]\n",
    "            tre_before = results[3]\n",
    "            tre12 = results[4]\n",
    "            mse12_image_before = results[5]\n",
    "            mse12_image = results[6]\n",
    "            ssim12_image_before = results[7]\n",
    "            ssim12_image = results[8]\n",
    "\n",
    "            # write metrics to csv file\n",
    "            with open(csv_file, 'a', newline='') as file:\n",
    "                writer = csv.writer(file) # TODO: might need to export true & predicted affine parameters too\n",
    "                writer.writerow([i, mse_before, mse12, tre_before, tre12, mse12_image_before, mse12_image, ssim12_image_before, ssim12_image])\n",
    "\n",
    "    # delete all txt files in output_dir\n",
    "    for file in os.listdir(output_dir):\n",
    "        if file.endswith(\".txt\"):\n",
    "            os.remove(os.path.join(output_dir, file))\n",
    "\n",
    "# timestamp = datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "metrics = test(model, model_params, timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spppt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
